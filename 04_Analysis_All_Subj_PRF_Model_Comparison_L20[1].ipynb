{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d049409",
   "metadata": {},
   "source": [
    "# Inter-Group Analysis - All Subjects and Saliency Data Predictions (Based on First Fixation Ground Truth Data, All Fixations Ground Truth Data, DeepGaze IIE - Saliency Model) \n",
    "\n",
    "Ground Truth Eye Tracking and DeepGaze IIE \n",
    "\n",
    "- Imports and path directions\n",
    "- Sorting all ROIs according to their neuroanatomical order during visual saliency processing \n",
    "- Now mediate (arithmetic median) the results over the whole group. \n",
    "- One-Sample t-test for df_mean_roi_stats (DataFrame that stores over all ROIs, the corresponding Sal_model and the meaned r-values)\n",
    "- One-Sample t-test for df_mean_roi_stats (DataFrame that stores for ROIs, the corresponding Sal_model and the meaned r-values)\n",
    "- Visualize the r-values over all ROIs \n",
    "- Plot the mean correlation values for each ROI with significance stars and error bars\n",
    "- Plot same barplot with confidence intervals and significance stars for ground truth eye tracking over all subjects.\n",
    "- Plot same barplot with confidence intervals and significance stars for DeepGaze over all subjects. \n",
    "- Perform plots for single subjects \n",
    "- Rank df_mean_roi_stats for the highest and lowest ROI value \n",
    "- Paired t-tests: Is the correlation of the two saliency models (DeepGaze IIE or GroudTruthEyeTrackingData) significantly different?\n",
    "- Repeated Measures ANOVA to evaluate the performance of all three models \n",
    "- Post-hoc: Paired t-tests (undirected), for each ROI, of the r values for DeepGaze and GroundTruthEyeTracking differ significantly across subjects.\n",
    "- Model comparison averaged over all ROIs undirected paired t-tests \n",
    "- Now execution of directed t-tests\n",
    "- Plotting of model difference (Mean r across all ROIs)\n",
    "\n",
    "Written by Lisa Heinemann  \n",
    "Last edited: 19/05/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d074eed",
   "metadata": {},
   "source": [
    "Imports and Path directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf936fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy.stats import t\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.multitest import multipletests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set roots relative to the base_dir to gain access to the NSD Dataset, \n",
    "# Create a Path object for the base directory pub\n",
    "base_dir = Path('/gpfs01/bartels/group/lheinemann/saliency-nsd-pub').expanduser()\n",
    "\n",
    "# Second Base_dir for the PRF Model project \n",
    "base_dir_nsd = Path('/gpfs01/bartels/group/nsd_dataset')\n",
    "############################################################################################################\n",
    "NSD_DATA_ROOT  = base_dir_nsd / 'nsddata'\n",
    "\n",
    "STIM_ROOT_NSD = NSD_DATA_ROOT / 'stimuli/nsd'\n",
    "stim_file = STIM_ROOT_NSD / 'nsd_stimuli.hdf5'\n",
    "shared1000_file = STIM_ROOT_NSD / 'shared1000.tsv'\n",
    "\n",
    "exp_design_file = NSD_DATA_ROOT / 'experiments/nsd/nsd_expdesign.mat'\n",
    "nsd_stiminfo_file = NSD_DATA_ROOT / 'experiments/nsd/nsd_stim_info_merged.csv'\n",
    "\n",
    "print(nsd_stiminfo_file)\n",
    "DATA_PATH = Path('/gpfs01/bartels/user/lheinemann/nsd-static-saliency/data')\n",
    "print(DATA_PATH)\n",
    "\n",
    "# Regions of Interest Path \n",
    "ROI_PATH = NSD_DATA_ROOT/ 'ppdata/'\n",
    "\n",
    "#ROI_PATH = NSD_ROOT/ 'ppdata/'\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "# Results Path for the Corrleation Plots\n",
    "RESULTS_PATH = base_dir / f'results/Plots_Correlation_nsd_all_shared1000'\n",
    "#RESULTS_PATH_subj = base_dir / f'results/Plots_Correlation_nsd_all_shared1000/subj0{sub_num}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d328876",
   "metadata": {},
   "source": [
    "## Sorting all ROIs according to their neuroanatomical order during visual saliency processing \n",
    "\n",
    "See explanation of the sorting in Notebook 03_Analysis_corr_per_subject.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rois \n",
    "all_rois = ['v1', 'v2', 'v3', 'v4', 'ofa', 'ffa1', 'ffa2', 'mtl_faces', 'atl', 'eba', 'fba1', 'fba2', 'mtl_bodies', 'opa', 'ppa',\n",
    "          'rsc', 'owfa', 'vwfa_1', 'vwfa_2', 'mfs_words', 'mtl_words', 'vo1', 'vo2', 'phc1', 'phc2', 'mst', \n",
    "          'hmt', 'lo2', 'lo1', 'v3b', 'v3a', 'ips0', 'ips1', 'ips2', 'ips3', 'ips4', 'ips5', 'spl1', 'fef']\n",
    "\n",
    "# Count the number of rois \n",
    "len(all_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d49e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the ROIs to context relevant sorting - from early vision areas to higher order visual areas\n",
    "\n",
    "# Define the order of ROIs based on the context\n",
    "sorted_rois = [\n",
    "    # Early visual areas - medial occipital\n",
    "    'v1', 'v2', 'v3', 'v4',\n",
    "\n",
    "    # Mid-level visual regions \n",
    "    'vo1', 'vo2', 'lo1', 'lo2',\n",
    "\n",
    "    # Dorsal Regions\n",
    "    'v3a', 'v3b',\n",
    "    'hmt', 'mst',\n",
    "    'ips0', 'ips1', 'ips2', 'ips3', 'ips4', 'ips5',\n",
    "\n",
    "    # Higher-order processing areas \n",
    "    'spl1', 'phc1', 'phc2', 'fef', \n",
    "    #######################################################################\n",
    "    # Higher-level visual areas (category selective: faces, bodies, words, places)\n",
    "    # Faces\n",
    "    'ofa', 'ffa1', 'ffa2', 'mtl_faces', 'atl', \n",
    "    # Bodies\n",
    "    'eba', 'fba1', 'fba2', 'mtl_bodies',\n",
    "    # Words\n",
    "    'owfa', 'vwfa_1', 'vwfa_2', 'mfs_words', 'mtl_words',\n",
    "    # Places\n",
    "    'opa', 'ppa', 'rsc',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d98c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ROI categories and assign a color hue to each\n",
    "roi_categories = {\n",
    "    'Early visual areas':      (['v1', 'v2', 'v3', 'v4'], '#3465a4'), # dark blue\n",
    "    'Mid-level visual regions':        (['vo1', 'vo2', 'lo1', 'lo2'], '#389bb7'), # light blue\n",
    "    'Dorsal regions':          (['v3a', 'v3b', 'hmt', 'mst', 'ips0', 'ips1', 'ips2', 'ips3', 'ips4', 'ips5'], 'turquoise'),\n",
    "    'Higher-order processing': (['spl1', 'phc1', 'phc2', 'fef'], '#66c2a5'), #greenish teal same as in other plot\n",
    "    'Faces':                   (['ofa', 'ffa1', 'ffa2', 'mtl_faces', 'atl'], '#489775'), # soft dark green\n",
    "    'Bodies':                  (['eba', 'fba1', 'fba2', 'mtl_bodies'], 'lightgreen'),\n",
    "    'Words':                   (['owfa', 'vwfa_1', 'vwfa_2', 'mfs_words', 'mtl_words'], '#c1d27b'), #yellow-green\n",
    "    'Places':                  (['opa', 'ppa', 'rsc'], '#fc8d62'), # orange same as in other plot\n",
    "}\n",
    "\n",
    "# Create a mapping from ROI to color\n",
    "roi_color_map = {}\n",
    "for category, (rois, color) in roi_categories.items():\n",
    "    for roi in rois:\n",
    "        roi_color_map[roi] = color\n",
    "\n",
    "\n",
    "# Example: get color for each ROI in sorted_rois\n",
    "roi_colors = [roi_color_map.get(roi) for roi in sorted_rois]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b5bf9c",
   "metadata": {},
   "source": [
    "### Load the necessary data and indicate the paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9da1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load paths to correlation results for ground truth eye-tracking data in every subject\n",
    "gt_eyetracking_paths = [RESULTS_PATH / f'subj0{sub_num}/roi_means_subj0{sub_num}_GroundTruthEyeTracking.csv' \\\n",
    "                        for sub_num in range(1, 9)]\n",
    "\n",
    "gt_eyetracking_paths_all_fix = [RESULTS_PATH / f'subj0{sub_num}/roi_means_subj0{sub_num}_AllFixations.csv' \\\n",
    "                        for sub_num in range(1, 9)]\n",
    "\n",
    "# Load paths to correlation results for DeepGaze in every subject\n",
    "deepgaze_data_paths = [RESULTS_PATH / f'subj0{sub_num}/roi_means_subj0{sub_num}_DeepGaze.csv' \\\n",
    "                    for sub_num in range(1, 9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11096ee",
   "metadata": {},
   "source": [
    "# Now mediate (arithmetic median) the results over the whole group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f417bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_subject_roi_stats(deepgaze_data_paths, gt_eyetracking_paths, gt_eyetracking_paths_all_fix):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - subject_files: List of file paths to subject-wise ROI stats CSVs.\n",
    "\n",
    "    Returns:\n",
    "    - df_mean_roi_stats: A DataFrame containing the mean r values and p-values across subjects for all ROIs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read first and second column from CSV file and label them 'ROI' and 'pearsonr'. Prepend a column called\n",
    "    # 'subject' and fill it with the subject number, also add a column called 'sal_model' and fill it with the saliency model name\n",
    "\n",
    "    \n",
    "    gt_df = pd.concat([pd.read_csv(path, usecols=[0, 1], names=['ROI', 'pearsonr'], header=None, skiprows=1).assign(subject=sub_num, sal_model='GroundTruthEyeTracking') \\\n",
    "                        for sub_num, path in enumerate(gt_eyetracking_paths, start=1)],  ignore_index=True)\n",
    "    gt_df_all_fix = pd.concat([pd.read_csv(path, usecols=[0, 1], names=['ROI', 'pearsonr'], header=None, skiprows=1).assign(subject=sub_num, sal_model='AllFixations') \\\n",
    "                        for sub_num, path in enumerate(gt_eyetracking_paths_all_fix, start=1)],  ignore_index=True)\n",
    "    dg_df = pd.concat([pd.read_csv(path, usecols=[0, 1], names=['ROI', 'pearsonr'], header=None, skiprows=1).assign(subject=sub_num, sal_model='DeepGaze') \\\n",
    "                    for sub_num, path in enumerate(deepgaze_data_paths, start=1)], ignore_index=True)\n",
    "    ########################## Merge the two DataFrames on 'ROI' and 'subject' columns ################\n",
    "    \n",
    "    # Concatenate DeepGaze and GroundTruthEyeTracking DataFrames\n",
    "    all_df = pd.concat([gt_df, gt_df_all_fix, dg_df], ignore_index=True)\n",
    "    # Sort Rois by the order defined in sorted_rois\n",
    "    all_df['ROI'] = pd.Categorical(all_df['ROI'], categories=sorted_rois, ordered=True)\n",
    "    # Sort the DataFrame by the custom ROI order\n",
    "    all_df = all_df.sort_values(by='ROI', ascending=True)\n",
    "    # Sort by subject and sal_model for clear grouping\n",
    "    all_df = all_df.sort_values(['subject', 'sal_model']).reset_index(drop=True)\n",
    "\n",
    "    # Sort by ROI, subject, and add sal_model for clear grouping\n",
    "    all_df = all_df.sort_values(['ROI', 'subject', 'sal_model']).reset_index(drop=True)\n",
    "\n",
    "    # Add the standard deviation of the correlation coefficients for each ROI and saliency model\n",
    "    all_df['std_pearsonr'] = all_df.groupby(['ROI', 'sal_model'])['pearsonr'].transform(lambda x: np.std(x, ddof=1))\n",
    "    # Eddge case handling \n",
    "    all_df['std_pearsonr'] = all_df['std_pearsonr'].fillna(0)  # Fill NaN values with 0\n",
    "    all_df['std_pearsonr'] = all_df['std_pearsonr'].replace([np.inf, -np.inf], 0)  # Replace inf values with 0\n",
    "\n",
    "\n",
    "    ############################## Calculate DataFrame  ############################################################\n",
    "\n",
    "    # Compute mean r and p-values across subjects for each ROI, and Saliency model - Using Fishers z-transformation\n",
    "    df_mean_roi_stats = all_df.groupby(['ROI', 'sal_model']).agg(\n",
    "        Mean_r=('pearsonr', lambda x: np.tanh(np.mean(np.arctanh(x.dropna()))))\n",
    "    ).reset_index()\n",
    "\n",
    "    # Ensure ROI column is categorical with the defined order\n",
    "    df_mean_roi_stats['ROI'] = pd.Categorical(df_mean_roi_stats['ROI'], categories=sorted_rois, ordered=True)\n",
    "\n",
    "    # Add the standard deviation of the correlation coefficients for each ROI and saliency model\n",
    "    df_mean_roi_stats['std_pearsonr'] = all_df.groupby(['ROI', 'sal_model'])['std_pearsonr'].mean().values\n",
    "    # Edges case handling\n",
    "    df_mean_roi_stats['std_pearsonr'] = df_mean_roi_stats['std_pearsonr'].fillna(0)  # Fill NaN values with 0\n",
    "    df_mean_roi_stats['std_pearsonr'] = df_mean_roi_stats['std_pearsonr'].replace([np.inf, -np.inf], 0)  # Replace inf values with 0\n",
    "\n",
    "    # Sort the DataFrame by the custom ROI order\n",
    "    df_mean_roi_stats = df_mean_roi_stats.sort_values(by='ROI', ascending=True)\n",
    "\n",
    "    #Save the accumulated subjectwwise DataFrame to a CSV file\n",
    "    all_df.to_csv(RESULTS_PATH / f'all_roi_all_subjects_all.csv', index=False)\n",
    "\n",
    "    # Save the aggregated DataFrame to a CSV file\n",
    "    df_mean_roi_stats.to_csv(RESULTS_PATH / f'all_roi_all_subjects_all_means.csv', index=False)\n",
    "   \n",
    "    return all_df, df_mean_roi_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb828af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function call\n",
    "all_df, df_mean_roi_stats = aggregate_subject_roi_stats(deepgaze_data_paths, gt_eyetracking_paths, gt_eyetracking_paths_all_fix)\n",
    "print(df_mean_roi_stats.head())  # Display the first few rows of the aggregated DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ecf8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_roi_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fd6e6e",
   "metadata": {},
   "source": [
    "## One-Sample t-test for df_mean_roi_stats (DataFrame that stores over all ROIs, the corresponding Sal_model and the meaned r-values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c3f0c",
   "metadata": {},
   "source": [
    "This tests is valid to test each model vs. 0. \n",
    "For each saliency model, is the average of its ROI-mean -correlations significantly greater than zero? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-sample t-test: Are mean r-values across ROIs significantly > 0 for each saliency model?\n",
    "results = []\n",
    "for sal_model in df_mean_roi_stats['sal_model'].unique():\n",
    "    # Get mean r-values for all ROIs for this saliency model\n",
    "    mean_r_vals = df_mean_roi_stats[df_mean_roi_stats['sal_model'] == sal_model]['Mean_r'].dropna()\n",
    "    # Fisher z-transform for r-values\n",
    "    z_vals = np.arctanh(mean_r_vals)\n",
    "    # Perform one-sample t-test against 0 (randomness)\n",
    "    t_stat, p_value = ttest_1samp(z_vals, popmean=0, alternative='greater')\n",
    "    print(f\"Saliency model: {sal_model} | t-stat: {t_stat:.3f} | p-value: {p_value:.4f}\")\n",
    "    results.append({'sal_model': sal_model, 't_stat': t_stat, 'p_value': p_value})\n",
    "\n",
    "# Apply the FDR correction to the p-values\n",
    "p_values = [res['p_value'] for res in results]\n",
    "\n",
    "# Apply Holm Sidak correction to the p-values\n",
    "_, corrected_p_values = multipletests(p_values, method='holm-sidak')[:2]\n",
    "for i, res in enumerate(results):\n",
    "    res['hs_p_value'] = corrected_p_values[i]\n",
    "    res['significant'] = corrected_p_values[i] < 0.05\n",
    "       \n",
    "# Convert results to DataFrame for reporting or saving\n",
    "t_test_results_df = pd.DataFrame(results)\n",
    "print(t_test_results_df)\n",
    "\n",
    "# Optionally, save to CSV\n",
    "#t_test_results_df.to_csv(RESULTS_PATH / 'mean_r_across_rois_ttest_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a647fa32",
   "metadata": {},
   "source": [
    "### Consistency with Paired T-Test Results\n",
    "\n",
    "You mentioned that a paired t-test revealed that the 'all-fixations' condition outperformed the 'first fixations' condition. Let's consider how the one-sample t-test results (from cell 16) could align with this finding:\n",
    "\n",
    "*   **Direct Comparison:** A paired t-test directly compares the two conditions (e.g., 'all-fixations' vs. 'first fixations' for the same subjects or items). This test is the most direct way to determine if one condition significantly outperforms the other.\n",
    "*   **Individual Condition Performance:** The one-sample t-tests you performed assess each condition individually against a specific reference point (e.g., testing if the mean performance of 'all-fixations' is significantly different from zero, and separately, if the mean performance of 'first fixations' is significantly different from zero).\n",
    "\n",
    "**How the one-sample t-tests can be consistent with the paired t-test:**\n",
    "\n",
    "The results from the one-sample t-tests can be consistent with the paired t-test finding if, for example:\n",
    "\n",
    "1.  The one-sample t-test for **'all-fixations'** shows a statistically significant positive mean (e.g., significantly greater than zero), indicating good performance.\n",
    "2.  The one-sample t-test for **'first fixations'** shows:\n",
    "    *   A positive mean that is also statistically significant but perhaps of a smaller magnitude than that for 'all-fixations', OR\n",
    "    *   A mean that is not statistically significantly different from zero, suggesting its performance isn't reliably above the reference point, OR\n",
    "    *   In some cases, even a mean that is significantly *less* than the reference if the outperformance is very stark.\n",
    "\n",
    "If the 'all-fixations' condition demonstrates a notably stronger or more reliable positive effect in its individual one-sample t-test compared to the 'first fixations' condition, this would support and be consistent with the paired t-test conclusion that 'all-fixations' outperformed 'first fixations'.\n",
    "\n",
    "While the one-sample t-tests look at each condition in isolation against a benchmark, their relative outcomes can provide corroborating evidence for the direct comparison made by the paired t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd255c6",
   "metadata": {},
   "source": [
    "## One-Sample t-test for df_mean_roi_stats (DataFrame that stores for ROIs, the corresponding Sal_model and the meaned r-values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a95350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-sample t-test for each single ROI (across subjects), for each saliency model\n",
    "single_roi_ttest_results = []\n",
    "\n",
    "for roi in df_mean_roi_stats['ROI'].unique():\n",
    "    for sal_model in df_mean_roi_stats['sal_model'].unique():\n",
    "        # Get mean r-values for this ROI and saliency model (across subjects)\n",
    "        roi_rvals = all_df[\n",
    "            (all_df['ROI'] == roi) &\n",
    "            (all_df['sal_model'] == sal_model)\n",
    "        ]['pearsonr'].dropna()\n",
    "        if len(roi_rvals) > 1:  # t-test requires at least 2 values\n",
    "            z_vals = np.arctanh(roi_rvals)\n",
    "            t_stat, p_value = ttest_1samp(z_vals, popmean=0, alternative='greater')\n",
    "            #print(f\"ROI: {roi} | {sal_model}: t={t_stat:.3f}, p={p_value:.4f}, n={len(z_vals)}\")\n",
    "            single_roi_ttest_results.append({\n",
    "                'ROI': roi,\n",
    "                'sal_model': sal_model,\n",
    "                't_stat': t_stat,\n",
    "                'p_value': p_value,\n",
    "                'n_subjects': len(z_vals)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"ROI: {roi} | {sal_model}: Not enough subjects for t-test.\")\n",
    "\n",
    "# Apply the FDR correction to the p-values\n",
    "p_values = [res['p_value'] for res in single_roi_ttest_results]\n",
    "_, corrected_p_values = multipletests(p_values, method='fdr_bh')[:2]\n",
    "for i, res in enumerate(single_roi_ttest_results):\n",
    "    res['fdr_p_value'] = corrected_p_values[i]\n",
    "    res['significant'] = corrected_p_values[i] < 0.05\n",
    "\n",
    "# Convert to DataFrame for reporting or saving\n",
    "df_roi_stats_fdr = pd.DataFrame(single_roi_ttest_results)\n",
    "\n",
    "# Define the desired order for saliency models\n",
    "model_order = ['GroundTruthEyeTracking', 'AllFixations', 'DeepGaze']\n",
    "\n",
    "# Convert 'sal_model' to a categorical type with the specified order\n",
    "# Ensure pandas (pd) is imported. If not, you might need to add 'import pandas as pd' earlier in the cell or notebook.\n",
    "df_roi_stats_fdr['sal_model'] = pd.Categorical(df_roi_stats_fdr['sal_model'], categories=model_order, ordered=True)\n",
    "\n",
    "# Sort the DataFrame first by ROI (to keep ROIs grouped) and then by the custom sal_model order\n",
    "df_roi_stats_fdr = df_roi_stats_fdr.sort_values(by=['ROI', 'sal_model'])\n",
    "\n",
    "print(df_roi_stats_fdr)\n",
    "\n",
    "# Optionally, save to CSV\n",
    "df_roi_stats_fdr.to_csv(RESULTS_PATH / 'df_roi_stats_fdr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd09d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roi_stats_fdr\n",
    "# Count the number of significant ROIs for each saliency model\n",
    "significant_counts = df_roi_stats_fdr[df_roi_stats_fdr['significant']].groupby('sal_model')['ROI'].count()\n",
    "print(\"Number of significant ROIs per saliency model:\")\n",
    "print(significant_counts)\n",
    "\n",
    "# Print the p-values of the significant ROIs\n",
    "significant_rois = df_roi_stats_fdr[df_roi_stats_fdr['significant']]\n",
    "print(\"Significant ROIs and their p-values:\")\n",
    "print(significant_rois[['ROI', 'sal_model', 'fdr_p_value']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b938817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roi_stats_fdr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e4736",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc97fc",
   "metadata": {},
   "source": [
    "## One-Sample *t*-test for df_mean_roi_stats (DataFrame that stores for ROIs, the corresponding Sal-model and the meaned r-values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0140ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Define ROI categories (already in your code)\n",
    "roi_categories = {\n",
    "    \"Visual ROIs\": [\"v1\", \"v2\", \"v3\", \"v4\"],\n",
    "    \"FLOC Faces ROIs\": [\"ofa\", \"ffa1\", \"ffa2\", \"atl\"],\n",
    "    \"FLOC Words ROIs\": [\"eba\", \"fba1\", \"fba2\"],\n",
    "    \"FLOC Places ROIs\": [\"opa\", \"ppa\", \"rsc\"],\n",
    "    \"FLOC Bodies ROIs\": [\"owfa\", \"vwfa_1\", \"vwfa_2\", \"mfs_words\", \"mtl_words\"],\n",
    "    \"Ventral Temporal ROIs\": [\"vo1\", \"vo2\", \"phc1\", \"phc2\"],\n",
    "    \"Dorso Lateral ROIs\": [\"v3a\", \"v3b\", \"lo2\", \"lo1\"],\n",
    "    \"Parietal Frontal ROIs\": [\"ips0\", \"ips1\", \"ips2\", \"ips3\", \"ips4\", \"ips5\", \"spl1\", \"fef\"]\n",
    "}\n",
    "\n",
    "group_ttest_results = []\n",
    "\n",
    "for group_name, roi_list in roi_categories.items():\n",
    "    for sal_model in df_mean_roi_stats['sal_model'].unique():\n",
    "        # Select mean r-values for this group and saliency model\n",
    "        group_rvals = df_mean_roi_stats[\n",
    "            (df_mean_roi_stats['ROI'].isin(roi_list)) &\n",
    "            (df_mean_roi_stats['sal_model'] == sal_model)\n",
    "        ]['Mean_r'].dropna()\n",
    "        if len(group_rvals) > 1:  # t-test requires at least 2 values\n",
    "            z_vals = np.arctanh(group_rvals)\n",
    "            t_stat, p_value = ttest_1samp(z_vals, popmean=0, alternative='greater')\n",
    "            print(f\"{group_name} | {sal_model}: t={t_stat:.3f}, p={p_value:.4f}, n={len(z_vals)}\")\n",
    "            group_ttest_results.append({\n",
    "                'Group': group_name,\n",
    "                'sal_model': sal_model,\n",
    "                't_stat': t_stat,\n",
    "                'p_value': p_value,\n",
    "                'n_rois': len(z_vals)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"{group_name} | {sal_model}: Not enough ROIs for t-test.\")\n",
    "\n",
    "# Convert to DataFrame for reporting or saving\n",
    "group_ttest_results_df = pd.DataFrame(group_ttest_results)\n",
    "print(group_ttest_results_df)\n",
    "\n",
    "# Optionally, save to CSV\n",
    "#group_ttest_results_df.to_csv(RESULTS_PATH / 'group_mean_r_ttest_results.csv', index=False) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9e5785",
   "metadata": {},
   "source": [
    "## Visualize the r-values over all ROIs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981bba1",
   "metadata": {},
   "source": [
    "Matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f1d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean correlation values for each ROI with significance stars\n",
    "def plot_mean_correlation_with_significance_all_subjects(df_mean_roi_stats,df_roi_stats_fdr):\n",
    "    \"\"\"\n",
    "    Plot the mean correlation values for each ROI with significance stars.\n",
    "\n",
    "    Parameters:\n",
    "    - df_mean_roi_stats: DataFrame containing mean r values across subjects for all ROIs.\n",
    "    - df_roi_stats_fdr: DataFrame containing FDR-corrected p-values for each ROI.\n",
    "    \"\"\"\n",
    "    # Extract ROI names, mean r values, and mean p-values\n",
    "    rois = df_mean_roi_stats['ROI']\n",
    "    mean_r_values = df_mean_roi_stats['Mean_r']\n",
    "    p_values = df_roi_stats_fdr['fdr_p_value']\n",
    "\n",
    "    # Create the bar plot\n",
    "    plt.figure(figsize=(20, 10)) # Adjust the width and height of the overall figure size \n",
    "    bars = plt.bar(rois, mean_r_values, color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Adjust the y-limit to create space for significance stars\n",
    "    min_r_value = min(mean_r_values)\n",
    "    max_r_value = max(mean_r_values)\n",
    "    plt.ylim(min_r_value - 0.05, max_r_value + 0.02)  # Add extra space above and below the bars\n",
    "\n",
    "    # Add significance stars\n",
    "    for i, (bar, p_value) in enumerate(zip(bars, p_values)):\n",
    "        if p_value < 0.001:\n",
    "            significance = '***'\n",
    "        elif p_value < 0.01:\n",
    "            significance = '**'\n",
    "        elif p_value < 0.05:\n",
    "            significance = '*'\n",
    "        else:\n",
    "            significance = ''\n",
    "        \n",
    "        # Add the stars above the bar\n",
    "        if significance:\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,\n",
    "                     significance, ha='center', va='bottom', fontsize=12, color='red')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('ROIs', fontsize=7)\n",
    "    plt.ylabel('Mean Correlation (r)', fontsize=10)\n",
    "    plt.title(f'Mean Correlation with Significance Across Subjects - Sal_mod_{sal_model}', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0dc6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function call\n",
    "plot_mean_correlation_with_significance_all_subjects(df_mean_roi_stats,df_roi_stats_fdr)\n",
    "plt.xticks(rotation=60, fontsize=9)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig(RESULTS_PATH / f'mean_correlation_with_significance_all_subjects_fdr_corrected_{sal_model}.png', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe41469",
   "metadata": {},
   "source": [
    "# Plot the mean correlation values for each ROI with significance stars and error bars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff51d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the fdr corrected p values of df_roi_stats_fdr to all_df dataframe according to the roi \n",
    "# and sal_model to create a comprhensive plot \n",
    "############################################################################\n",
    "\n",
    "# Create a lookup for p-values\n",
    "pval_lookup = {(row['ROI'], row['sal_model']): row['fdr_p_value'] for _, row in df_roi_stats_fdr.iterrows()}\n",
    "# Add the p-values to all_df\n",
    "all_df['fdr_p_value'] = all_df.apply(lambda row: pval_lookup.get((row['ROI'], row['sal_model'])), axis=1)\n",
    "\n",
    "print(all_df.head())  # Display the first few rows of the updated DataFrame\n",
    "print(all_df.tail()) # Display the last few rows of the updated DataFrame\n",
    "\n",
    "# Save the updated DataFrame with FDR correction results\n",
    "# all_df.to_csv(RESULTS_PATH / f'roi_means_all_subjects_fdr_corrected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57585261",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # With automatic error bar, the errorbar printed in the plot below is more accurate\n",
    "\n",
    "sns.catplot(data=all_df, x='ROI', y='pearsonr', hue='sal_model',\n",
    "            kind='bar', height=6, aspect=2, palette='Set2', \n",
    "            estimator=lambda x: np.tanh(np.mean(np.arctanh(x))))\n",
    "# save the plot to a file\n",
    "#plt.savefig(RESULTS_PATH / f'combined_mean_correlation_sig_all_subjects_fdr_corrected.png', dpi=300)  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c21e85e",
   "metadata": {},
   "source": [
    "## Plot same barplot with confidence intervals and significance stars for ground truth eye tracking over all subjects. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7534ff",
   "metadata": {},
   "source": [
    "Blue-Green-Purple-Lightred-Orange-Gold Design for Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd5ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" roi_categories = {\n",
    "    'Early visual areas':      (['v1', 'v2', 'v3', 'v4'], '#3465a4'), # navy blue\n",
    "    'Mid-level visual':        (['vo1', 'vo2', 'lo1', 'lo2'], '#389bb7'), # light blue\n",
    "    'Dorsal regions':          (['v3a', 'v3b', 'hmt', 'mst', 'ips0', 'ips1', 'ips2', 'ips3', 'ips4', 'ips5'], '#66c2a5'), #greenish teal same as in other plot\n",
    "    'Higher-order processing': (['spl1', 'phc1', 'phc2', 'fef'], '#b2df8a'), # green\n",
    "    'Faces':                   (['ofa', 'ffa1', 'ffa2', 'mtl_faces', 'atl'],  '#b07aa1'), #purple \n",
    "    'Bodies':                  (['eba', 'fba1', 'fba2', 'mtl_bodies'], '#ff9999'), # light red\n",
    "    'Words':                   (['owfa', 'vwfa_1', 'vwfa_2', 'mfs_words', 'mtl_words'], '#fc8d62'), # orange same as in other plot \n",
    "    'Places':                  (['opa', 'ppa', 'rsc'], '#f7c873'), # gold\n",
    "}\n",
    "# Create a mapping from ROI to color\n",
    "roi_color_map = {}\n",
    "for category, (rois, color) in roi_categories.items():\n",
    "    for roi in rois:\n",
    "        roi_color_map[roi] = color\n",
    "\n",
    "\n",
    "# Example: get color for each ROI in sorted_rois\n",
    "roi_colors = [roi_color_map.get(roi) for roi in sorted_rois] \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788fd941",
   "metadata": {},
   "source": [
    "Green-Blue-Turqoise-Orange Design for Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da63cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_categories = {\n",
    "    'Early visual areas':      (['v1', 'v2', 'v3', 'v4'], '#3465a4'), # dark blue\n",
    "    'Mid-level visual regions':        (['vo1', 'vo2', 'lo1', 'lo2'], '#56B4E9'), # light blue\n",
    "    'Dorsal regions':          (['v3a', 'v3b', 'hmt', 'mst', 'ips0', 'ips1', 'ips2', 'ips3', 'ips4', 'ips5'], 'turquoise'),\n",
    "    'Higher-order processing': (['spl1', 'phc1', 'phc2', 'fef'], '#f3e5ab'), #greenish teal same as in other plot\n",
    "    'Faces':                   (['ofa', 'ffa1', 'ffa2', 'mtl_faces', 'atl'], '#489775'), # soft dark green\n",
    "    'Bodies':                  (['eba', 'fba1', 'fba2', 'mtl_bodies'], 'lightgreen'),\n",
    "    'Words':                   (['owfa', 'vwfa_1', 'vwfa_2', 'mfs_words', 'mtl_words'], '#c1d27b'), #yellow-green\n",
    "    'Places':                  (['opa', 'ppa', 'rsc'], '#fc8d62'), # orange same as in other plot\n",
    "}\n",
    "\n",
    "# Create a mapping from ROI to color\n",
    "roi_color_map = {}\n",
    "for category, (rois, color) in roi_categories.items():\n",
    "    for roi in rois:\n",
    "        roi_color_map[roi] = color\n",
    "\n",
    "\n",
    "# Example: get color for each ROI in sorted_rois\n",
    "roi_colors = [roi_color_map.get(roi) for roi in sorted_rois]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf4df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eytracking_df = all_df[all_df['sal_model'] == 'GroundTruthEyeTracking'].copy()\n",
    "\n",
    "#sns.set_theme(style=\"whitegrid\")\n",
    "# Map ROI to category\n",
    "roi_to_category = {}\n",
    "for category, (rois, _) in roi_categories.items():\n",
    "    for roi in rois:\n",
    "        roi_to_category[roi] = category\n",
    "eytracking_df['roi_category'] = eytracking_df['ROI'].map(roi_to_category)\n",
    "\n",
    "# Use hue and a palette mapping category to color\n",
    "category_palette = {cat: color for cat, (_, color) in roi_categories.items()}\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "ax = sns.barplot(\n",
    "    data=eytracking_df, x='ROI', y='pearsonr',\n",
    "    hue='roi_category', palette=category_palette,\n",
    "    estimator=lambda x: np.tanh(np.mean(np.arctanh(x)))\n",
    ")\n",
    "# Ensure gridlines are behind the bars\n",
    "ax.set_axisbelow(True)\n",
    "# Add vertical gridlines\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"ROI\")\n",
    "plt.ylabel(\"Mean Correlation (r)\")\n",
    "plt.title(\"Mean Correlation for All Subjects per ROI - Ground Truth Eye Tracking First Fixations)\")\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "# Define custom ROI label mapping - so that the labels of the plot are coherent with the thesis and literature \n",
    "roi_label_map = {\n",
    "    'v4': 'hV4',\n",
    "    'hmt': 'hMT',\n",
    "    'mtl_faces': 'MTL-faces',\n",
    "    'mtl_bodies': 'MTL-bodies',\n",
    "    'mfs_words': 'MFS-words',\n",
    "    'mtl_words': 'MTL-words',\n",
    "    'owfa': 'OVWFA',\n",
    "    # Add more mappings if needed\n",
    "}\n",
    "\n",
    "# Get current x-tick labels (original ROI names)\n",
    "original_roi_order = [label.get_text() for label in ax.get_xticklabels()]\n",
    "\n",
    "# Apply custom label mapping for display\n",
    "custom_labels = [roi_label_map.get(lbl, lbl.upper()) for lbl in original_roi_order]\n",
    "ax.set_xticklabels(custom_labels, rotation=60)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylim(-0.1,0.18)\n",
    "\n",
    "# Move the legend to the top right corner\n",
    "if ax.legend_ is not None:\n",
    "    ax.legend_.set_title(\"ROI category\")\n",
    "    ax.legend_.set_bbox_to_anchor((1.05, 1))\n",
    "\n",
    "\"\"\" # Use original ROI names for lookup, but display custom labels\n",
    "roi_order = original_roi_order\n",
    "saliency_order = [t.get_text() for t in g._legend.texts]\n",
    "n_roi = len(roi_order)\n",
    "n_sal = len(saliency_order) \"\"\"\n",
    "#######################################################################################################################################\n",
    "# Add significance stars using FDR-corrected p-values\n",
    "for i, bar in enumerate(ax.patches[:len(original_roi_order)]):\n",
    "    roi = original_roi_order[i]\n",
    "    match = eytracking_df[eytracking_df['ROI'] == roi]\n",
    "    if match.empty or pd.isnull(match['fdr_p_value'].values[0]):\n",
    "        continue\n",
    "    p_value = match['fdr_p_value'].values[0]\n",
    "    if p_value < 0.001:\n",
    "        significance = '***'\n",
    "    elif p_value < 0.01:\n",
    "        significance = '**'\n",
    "    elif p_value < 0.05:\n",
    "        significance = '*'\n",
    "    else:\n",
    "        significance = ''\n",
    "    if significance:\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height() + 0.04,  # Print higher above the bar\n",
    "            significance,\n",
    "            ha='center', va='bottom',\n",
    "            fontsize=14, color='red'  # Changed color and font size\n",
    "        )\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig(RESULTS_PATH / 'ground_truth_eye_tracking_mean_correlation_sig_all_subjects_fdr_corrected.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(RESULTS_PATH / 'ground_truth_eye_tracking_mean_correlation_sig_all_subjects_fdr_corrected.svg', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2a11f3",
   "metadata": {},
   "source": [
    "## Plot same barplot with confidence intervals and significance stars for DeepGaze over all subjects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77eeab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepgaze_df = all_df[all_df['sal_model'] == 'DeepGaze'].copy()\n",
    "\n",
    "# Map ROI to category\n",
    "roi_to_category = {}\n",
    "for category, (rois, _) in roi_categories.items():\n",
    "    for roi in rois:\n",
    "        roi_to_category[roi] = category\n",
    "deepgaze_df['roi_category'] = deepgaze_df['ROI'].map(roi_to_category)\n",
    "\n",
    "# Use hue and a palette mapping category to color\n",
    "category_palette = {cat: color for cat, (_, color) in roi_categories.items()}\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "ax = sns.barplot(\n",
    "    data=deepgaze_df, x='ROI', y='pearsonr',\n",
    "    hue='roi_category', palette=category_palette,\n",
    "    estimator=lambda x: np.tanh(np.mean(np.arctanh(x)))\n",
    ")\n",
    "# Ensure gridlines are behind the bars\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Add vertical gridlines\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"ROI\")\n",
    "plt.ylabel(\"Mean Correlation (r)\")\n",
    "plt.title(\"Mean Correlation for All Subjects per ROI - DeepGaze IIE\")\n",
    "\n",
    "#######################################################################################################################################\n",
    "# Define custom ROI label mapping - so that the labels of the plot are coherent with the thesis and literature \n",
    "roi_label_map = {\n",
    "    'v4': 'hV4',\n",
    "    'hmt': 'hMT',\n",
    "    'mtl_faces': 'MTL-faces',\n",
    "    'mtl_bodies': 'MTL-bodies',\n",
    "    'mfs_words': 'MFS-words',\n",
    "    'mtl_words': 'MTL-words',\n",
    "    'owfa': 'OVWFA',\n",
    "    # Add more mappings if needed\n",
    "}\n",
    "\n",
    "# Get current x-tick labels (original ROI names)\n",
    "original_roi_order = [label.get_text() for label in ax.get_xticklabels()]\n",
    "\n",
    "# Apply custom label mapping for display\n",
    "custom_labels = [roi_label_map.get(lbl, lbl.upper()) for lbl in original_roi_order]\n",
    "ax.set_xticklabels(custom_labels, rotation=60)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylim(-0.1,0.18)\n",
    "\n",
    "# Move the legend to the top right corner\n",
    "if ax.legend_ is not None:\n",
    "    ax.legend_.set_title(\"ROI category\")\n",
    "    ax.legend_.set_bbox_to_anchor((1.05, 1))\n",
    "\n",
    "\"\"\" # Use original ROI names for lookup, but display custom labels\n",
    "roi_order = original_roi_order\n",
    "saliency_order = [t.get_text() for t in g._legend.texts]\n",
    "n_roi = len(roi_order)\n",
    "n_sal = len(saliency_order) \"\"\"\n",
    "#######################################################################################################################################\n",
    "# Add significance stars using FDR-corrected p-values\n",
    "for i, bar in enumerate(ax.patches[:len(original_roi_order)]):\n",
    "    roi = original_roi_order[i]\n",
    "    match = deepgaze_df[deepgaze_df['ROI'] == roi]\n",
    "    if match.empty or pd.isnull(match['fdr_p_value'].values[0]):\n",
    "        continue\n",
    "    p_value = match['fdr_p_value'].values[0]\n",
    "    if p_value < 0.001:\n",
    "        significance = '***'\n",
    "    elif p_value < 0.01:\n",
    "        significance = '**'\n",
    "    elif p_value < 0.05:\n",
    "        significance = '*'\n",
    "    else:\n",
    "        significance = ''\n",
    "    if significance:\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height() + 0.045,  # Print higher above the bar\n",
    "            significance,\n",
    "            ha='center', va='bottom',\n",
    "            fontsize=14, color='red'  # Changed color and font size\n",
    "        )\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig(RESULTS_PATH / 'deepgaze_mean_correlation_sig_all_subjects_fdr_corrected.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(RESULTS_PATH / 'deepgaze_mean_correlation_sig_all_subjects_fdr_corrected.svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48610772",
   "metadata": {},
   "source": [
    "same overall plot for all fixations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepgaze_df = all_df[all_df['sal_model'] == 'AllFixations'].copy()\n",
    "\n",
    "# Map ROI to category\n",
    "roi_to_category = {}\n",
    "for category, (rois, _) in roi_categories.items():\n",
    "    for roi in rois:\n",
    "        roi_to_category[roi] = category\n",
    "deepgaze_df['roi_category'] = deepgaze_df['ROI'].map(roi_to_category)\n",
    "\n",
    "# Use hue and a palette mapping category to color\n",
    "category_palette = {cat: color for cat, (_, color) in roi_categories.items()}\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "ax = sns.barplot(\n",
    "    data=deepgaze_df, x='ROI', y='pearsonr',\n",
    "    hue='roi_category', palette=category_palette,\n",
    "    estimator=lambda x: np.tanh(np.mean(np.arctanh(x)))\n",
    ")\n",
    "\n",
    "# Ensure gridlines are behind the bars\n",
    "ax.set_axisbelow(True)\n",
    "# Add vertical gridlines\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"ROI\")\n",
    "plt.ylabel(\"Mean Correlation (r)\")\n",
    "plt.title(\"Mean Correlation for All Subjects per ROI - All Fixations\")\n",
    "\n",
    "#######################################################################################################################################\n",
    "# Define custom ROI label mapping - so that the labels of the plot are coherent with the thesis and literature \n",
    "roi_label_map = {\n",
    "    'v4': 'hV4',\n",
    "    'hmt': 'hMT',\n",
    "    'mtl_faces': 'MTL-faces',\n",
    "    'mtl_bodies': 'MTL-bodies',\n",
    "    'mfs_words': 'MFS-words',\n",
    "    'mtl_words': 'MTL-words',\n",
    "    'owfa': 'OVWFA',\n",
    "    # Add more mappings if needed\n",
    "}\n",
    "\n",
    "# Get current x-tick labels (original ROI names)\n",
    "original_roi_order = [label.get_text() for label in ax.get_xticklabels()]\n",
    "\n",
    "# Apply custom label mapping for display\n",
    "custom_labels = [roi_label_map.get(lbl, lbl.upper()) for lbl in original_roi_order]\n",
    "ax.set_xticklabels(custom_labels, rotation=60)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylim(-0.1,0.18)\n",
    "\n",
    "# Move the legend to the top right corner\n",
    "if ax.legend_ is not None:\n",
    "    ax.legend_.set_title(\"ROI category\")\n",
    "    ax.legend_.set_bbox_to_anchor((1.05, 1))\n",
    "\n",
    "\"\"\" # Use original ROI names for lookup, but display custom labels\n",
    "roi_order = original_roi_order\n",
    "saliency_order = [t.get_text() for t in g._legend.texts]\n",
    "n_roi = len(roi_order)\n",
    "n_sal = len(saliency_order) \"\"\"\n",
    "\n",
    "#######################################################################################################################################\n",
    "# Add significance stars using FDR-corrected p-values\n",
    "for i, bar in enumerate(ax.patches[:len(original_roi_order)]):\n",
    "    roi = original_roi_order[i]\n",
    "    match = deepgaze_df[deepgaze_df['ROI'] == roi]\n",
    "    if match.empty or pd.isnull(match['fdr_p_value'].values[0]):\n",
    "        continue\n",
    "    p_value = match['fdr_p_value'].values[0]\n",
    "    if p_value < 0.001:\n",
    "        significance = '***'\n",
    "    elif p_value < 0.01:\n",
    "        significance = '**'\n",
    "    elif p_value < 0.05:\n",
    "        significance = '*'\n",
    "    else:\n",
    "        significance = ''\n",
    "    if significance:\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height() + 0.045,  # Print higher above the bar\n",
    "            significance,\n",
    "            ha='center', va='bottom',\n",
    "            fontsize=14, color='red'  # Changed color and font size\n",
    "        )\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig(RESULTS_PATH /'allFix_mean_correlation_sig_all_subjects_fdr_corrected.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(RESULTS_PATH /'allFix_mean_correlation_sig_all_subjects_fdr_corrected.svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17f9c47",
   "metadata": {},
   "source": [
    "# Perform plots for single subjects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb4e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the order of ROIs based on the context\n",
    "sorted_rois = [\n",
    "    # Early visual areas - medial occipital\n",
    "    'v1', 'v2', 'v3', 'v4',\n",
    "\n",
    "    # Mid-level visual regions \n",
    "    'vo1', 'vo2', 'lo1', 'lo2',\n",
    "\n",
    "    # Dorsal regions\n",
    "    'v3a', 'v3b',\n",
    "    'hmt', 'mst',\n",
    "    'ips0', 'ips1', 'ips2', 'ips3', 'ips4', 'ips5',\n",
    "\n",
    "    # Higher-order processing areas \n",
    "    'spl1', 'phc1', 'phc2', 'fef', \n",
    "    #######################################################################\n",
    "    # Higher-level visual areas (category selective: faces, bodies, words, places)\n",
    "\n",
    "    # Faces\n",
    "    'ofa', 'ffa1', 'ffa2', 'mtl_faces', 'atl', \n",
    "    # Bodies\n",
    "    'eba', 'fba1', 'fba2', 'mtl_bodies',\n",
    "    # Words\n",
    "    'owfa', 'vwfa_1', 'vwfa_2', 'mfs_words', 'mtl_words',\n",
    "    # Places\n",
    "    'opa', 'ppa', 'rsc',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdba531",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_num in range(1, 9):\n",
    "\n",
    "    # Subjectwise Data Path Storage\n",
    "\n",
    "    DATA_PATH_subj = DATA_PATH / f'subjectwise_data/subject0{sub_num}'\n",
    "    \n",
    "    # Load the numpy array that store voxelwise correlation values on the main diagonal\n",
    "\n",
    "    corr_md_subj_all_rois = np.load(DATA_PATH_subj/ f'corr_mat_all_rois_subj0{sub_num}.npy', allow_pickle = True) \n",
    "\n",
    "    corr_md_subj_all_rois_deepgaze = np.load(DATA_PATH_subj/ f'corr_mat_all_rois_deepgazeIIE_subj0{sub_num}.npy', allow_pickle = True)\n",
    "\n",
    "    corr_md_subj_all_rois_allFix = np.load(DATA_PATH_subj/ f'corr_mat_all_rois_allfixations_subj0{sub_num}.npy', allow_pickle = True)\n",
    "    # Convert corr_md_subj_all_rois (assumed 2D numpy array) to a DataFrame\n",
    "    corr_md_subj_all_rois_df = pd.DataFrame(corr_md_subj_all_rois, columns=[\"ROI\", \"r_value\",\"p_value\"])\n",
    "    # Inspect the shape and create the DataFrame with the correct number of columns\n",
    "    print(\"corr_md_subj_all_rois shape:\", corr_md_subj_all_rois.shape)\n",
    "\n",
    "    # If shape is (N, 3), add a third column name (e.g., \"p_value\")\n",
    "    corr_md_subj_all_rois_df = pd.DataFrame(\n",
    "        corr_md_subj_all_rois, columns=[\"ROI\", \"r_value\", \"p_value\"]\n",
    "\n",
    "    )\n",
    "    print(corr_md_subj_all_rois_df.head())\n",
    "\n",
    "    # Save the subjectwise DataFrame to a CSV file\n",
    "    corr_md_subj_all_rois_df.to_csv(DATA_PATH_subj / f'corr_mat_all_rois_ET_first_subj0{sub_num}.csv', index=False)\n",
    "    ############################################################ DeepGaze ###################################################\n",
    "    # Convert corr_md_subj_all_rois (assumed 2D numpy array) to a DataFrame\n",
    "    corr_md_subj_all_rois_df_dg = pd.DataFrame(corr_md_subj_all_rois_deepgaze, columns=[\"ROI\", \"r_value\",\"p_value\"])\n",
    "    # Inspect the shape and create the DataFrame with the correct number of columns\n",
    "    print(\"corr_md_subj_all_rois shape:\", corr_md_subj_all_rois_deepgaze.shape)\n",
    "\n",
    "    # If shape is (N, 3), add a third column name (e.g., \"p_value\")\n",
    "    corr_md_subj_all_rois_df_dg = pd.DataFrame(\n",
    "        corr_md_subj_all_rois_deepgaze, columns=[\"ROI\", \"r_value\", \"p_value\"]\n",
    "    )\n",
    "\n",
    "    print(corr_md_subj_all_rois_df_dg.head())\n",
    "\n",
    "    # Save the subjectwise DataFrame to a CSV file\n",
    "    corr_md_subj_all_rois_df_dg.to_csv(DATA_PATH_subj / f'corr_mat_all_rois_deepgazeIIE_subj0{sub_num}.csv', index=False)\n",
    "\n",
    "    ########################################################### All Fixations ###################################################\n",
    "    # Convert corr_md_subj_all_rois (assumed 2D numpy array) to a DataFrame\n",
    "    corr_md_subj_all_rois_df_allFix = pd.DataFrame(corr_md_subj_all_rois_allFix, columns=[\"ROI\", \"r_value\",\"p_value\"])\n",
    "    # Inspect the shape and create the DataFrame with the correct number of columns\n",
    "    print(\"corr_md_subj_all_rois shape:\", corr_md_subj_all_rois_allFix.shape)\n",
    "\n",
    "    # If shape is (N, 3), add a third column name (e.g., \"p_value\")\n",
    "    corr_md_subj_all_rois_df_allFix = pd.DataFrame(\n",
    "        corr_md_subj_all_rois_allFix, columns=[\"ROI\", \"r_value\", \"p_value\"]\n",
    "    )\n",
    "\n",
    "    print(corr_md_subj_all_rois_df_allFix.head())\n",
    "\n",
    "    # Save the subjectwise DataFrame to a CSV file\n",
    "    corr_md_subj_all_rois_df_allFix.to_csv(DATA_PATH_subj / f'corr_mat_all_rois_allFix_subj0{sub_num}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4699ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_md_subj_all_rois_df_dg\n",
    "corr_md_subj_all_rois_df\n",
    "corr_md_subj_all_rois_df_allFix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25cbf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_num in range(1, 9):\n",
    "    # Subjectwise Data Path Storage\n",
    "    DATA_PATH_subj = DATA_PATH / f'subjectwise_data/subject0{sub_num}'\n",
    "    # Filter for DeepGaze and the current subject\n",
    "    eytracking_df = pd.read_csv(DATA_PATH_subj / f'corr_mat_all_rois_ET_first_subj0{sub_num}.csv')\n",
    "    if eytracking_df.empty:    \n",
    "\n",
    "        print(f\"No data for subject {sub_num}\")\n",
    "        continue\n",
    "   \n",
    "    # Map ROI to category\n",
    "    roi_to_category = {}\n",
    "    for category, (rois, _) in roi_categories.items():\n",
    "        for roi in rois:\n",
    "            roi_to_category[roi] = category\n",
    "    eytracking_df['roi_category'] = eytracking_df['ROI'].map(roi_to_category)\n",
    "\n",
    "    # Create a grouped ROI order: all ROIs grouped by category order\n",
    "    grouped_roi_order = []\n",
    "    for category, (rois, _) in roi_categories.items():\n",
    "        grouped_roi_order.extend(rois)\n",
    "    # Filter to only those present in the DataFrame\n",
    "    grouped_roi_order = [roi for roi in grouped_roi_order if roi in eytracking_df['ROI'].values]\n",
    "\n",
    "\n",
    "    # Use hue and a palette mapping category to color\n",
    "    category_palette = {cat: color for cat, (_, color) in roi_categories.items()}\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    ax = sns.barplot(\n",
    "        data=eytracking_df, x='ROI', y='r_value',\n",
    "        hue='roi_category', palette=category_palette,\n",
    "        estimator=lambda x: np.tanh(np.mean(np.arctanh(x))),\n",
    "        errorbar='sd',  # Use standard deviation for error bars\n",
    "        order=grouped_roi_order\n",
    "    )\n",
    "    # Ensure gridlines are behind the bars\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # Add vertical gridlines\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.xlabel(\"ROI\")\n",
    "    plt.ylabel(\"Mean Correlation (r)\")\n",
    "    plt.title(f\"Mean Correlation per ROI - Eye Tracking First Fixation, Subject 0{sub_num}\")\n",
    "\n",
    "\n",
    "    #######################################################################################################################################\n",
    "    # Define custom ROI label mapping - so that the labels of the plot are coherent with the thesis and literature \n",
    "    roi_label_map = {\n",
    "        'v4': 'hV4',\n",
    "        'hmt': 'hMT',\n",
    "        'mtl_faces': 'MTL-faces',\n",
    "        'mtl_bodies': 'MTL-bodies',\n",
    "        'mfs_words': 'MFS-words',\n",
    "        'mtl_words': 'MTL-words',\n",
    "        'owfa': 'OVWFA',\n",
    "        # Add more mappings if needed\n",
    "    }\n",
    "\n",
    "    # Get current x-tick labels (original ROI names)\n",
    "    original_roi_order = [label.get_text() for label in ax.get_xticklabels()]\n",
    "\n",
    "    # Apply custom label mapping for display\n",
    "    custom_labels = [roi_label_map.get(lbl, lbl.upper()) for lbl in original_roi_order]\n",
    "    ax.set_xticklabels(custom_labels, rotation=60)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylim(-0.1,0.37)\n",
    "\n",
    "    # Move the legend to the top right corner\n",
    "    if ax.legend_ is not None:\n",
    "        ax.legend_.set_title(\"ROI category\")\n",
    "        ax.legend_.set_bbox_to_anchor((1.05, 1))\n",
    "\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.ylim(-0.1, 0.37)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Get the order of ROIs and hues as plotted\n",
    "    roi_order = [label.get_text() for label in ax.get_xticklabels()]\n",
    "    hue_order = list(deepgaze_df['roi_category'].dropna().unique())\n",
    "    n_hue = len(hue_order)\n",
    "    n_roi = len(roi_order)\n",
    "\n",
    "    ######################################################################################################################################\n",
    "    # Load the fdr_corrected p_values per ROI and subject from the subjectwiese df geneated in 03_analysis, while performing the ttest\n",
    "    # Create a lookup for p-values\n",
    "\n",
    "    for sub_num_inner_loop in range(1, 9): # Renamed to avoid conflict with outer loop sub_num\n",
    "        # Define the subject-specific results path dynamically \n",
    "        RESULTS_PATH_subj = RESULTS_PATH / f'subj0{sub_num_inner_loop}'\n",
    "        # Load the DataFrame with FDR-corrected p-values\n",
    "        # Assuming sal_model is defined elsewhere or you want to use a specific one\n",
    "        # For this example, I'll use a placeholder. You might need to adjust this.\n",
    "        current_sal_model = 'GroundTruthEyeTracking' # Placeholder\n",
    "        df_singlesub_fdr= pd.read_csv(RESULTS_PATH_subj / f'roi_means_subj0{sub_num_inner_loop}_{current_sal_model}_fdr_corrected.csv', index_col=False)\n",
    "\n",
    "    # Save the updated DataFrame with FDR correction results\n",
    "    \n",
    "    # Add significance stars using p-values\n",
    "    for i, bar in enumerate(ax.patches[:len(original_roi_order)]):\n",
    "        roi = original_roi_order[i]\n",
    "        match = df_singlesub_fdr[df_singlesub_fdr['ROI'] == roi]\n",
    "        \n",
    "    \n",
    "        if match.empty or pd.isnull(match['FDR-corrected p-value'].values[0]):\n",
    "            continue\n",
    "        p_value = match['FDR-corrected p-value'].values[0]\n",
    "        # Only print stars if the correlation (bar height) is positive\n",
    "        if bar.get_height() > 0:\n",
    "            if p_value < 0.001:\n",
    "                significance = '***'\n",
    "            elif p_value < 0.01:\n",
    "                significance = '**'\n",
    "            elif p_value < 0.05:\n",
    "                significance = '*'\n",
    "            else:\n",
    "                significance = ''\n",
    "            if significance:\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width() / 2,\n",
    "                    bar.get_height() + 0.01, # Adjusted y-offset for better placement\n",
    "                    significance,\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=14, color='red'\n",
    "                )\n",
    "\n",
    "    plt.savefig(RESULTS_PATH / f'eyetracking_firstFixations_mean_correlation_sig_subj0{sub_num}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(RESULTS_PATH / f'eyetracking_firstFixations_mean_correlation_sig_subj0{sub_num}.svg', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c0a1a",
   "metadata": {},
   "source": [
    "For Groundtruth all fixations - plots per subj "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e06c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_num in range(1, 9):\n",
    "    # Subjectwise Data Path Storage\n",
    "    DATA_PATH_subj = DATA_PATH / f'subjectwise_data/subject0{sub_num}'\n",
    "    # Filter for DeepGaze and the current subject\n",
    "    eytracking_df = pd.read_csv(DATA_PATH_subj / f'corr_mat_all_rois_allFix_subj0{sub_num}.csv')\n",
    "    \n",
    "    if eytracking_df.empty:\n",
    "        print(f\"No data for subject {sub_num}\")\n",
    "        continue\n",
    "   \n",
    "    # Map ROI to category\n",
    "    roi_to_category = {}\n",
    "    for category, (rois, _) in roi_categories.items():\n",
    "        for roi in rois:\n",
    "            roi_to_category[roi] = category\n",
    "    eytracking_df['roi_category'] = eytracking_df['ROI'].map(roi_to_category)\n",
    "\n",
    "    # Create a grouped ROI order: all ROIs grouped by category order\n",
    "    grouped_roi_order = []\n",
    "    for category, (rois, _) in roi_categories.items():\n",
    "        grouped_roi_order.extend(rois)\n",
    "    # Filter to only those present in the DataFrame\n",
    "    grouped_roi_order = [roi for roi in grouped_roi_order if roi in eytracking_df['ROI'].values]\n",
    "\n",
    "\n",
    "    # Use hue and a palette mapping category to color\n",
    "    category_palette = {cat: color for cat, (_, color) in roi_categories.items()}\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    ax = sns.barplot(\n",
    "        data=eytracking_df, x='ROI', y='r_value',\n",
    "        hue='roi_category', palette=category_palette,\n",
    "        estimator=lambda x: np.tanh(np.mean(np.arctanh(x))),\n",
    "        errorbar='sd',  # Use standard deviation for error bars\n",
    "        order=grouped_roi_order\n",
    "    )\n",
    "    # Ensure gridlines are behind the bars\n",
    "    ax.set_axisbelow(True)\n",
    "    # Add vertical gridlines\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.xlabel(\"ROI\")\n",
    "    plt.ylabel(\"Mean Correlation (r)\")\n",
    "    plt.title(f\"Mean Correlation per ROI - Eye Tracking All Fixations, Subject 0{sub_num}\")\n",
    "\n",
    "\n",
    "    #######################################################################################################################################\n",
    "    # Define custom ROI label mapping - so that the labels of the plot are coherent with the thesis and literature \n",
    "    roi_label_map = {\n",
    "        'v4': 'hV4',\n",
    "        'hmt': 'hMT',\n",
    "        'mtl_faces': 'MTL-faces',\n",
    "        'mtl_bodies': 'MTL-bodies',\n",
    "        'mfs_words': 'MFS-words',\n",
    "        'mtl_words': 'MTL-words',\n",
    "        'owfa': 'OVWFA',\n",
    "        # Add more mappings if needed\n",
    "    }\n",
    "\n",
    "    # Get current x-tick labels (original ROI names)\n",
    "    original_roi_order = [label.get_text() for label in ax.get_xticklabels()]\n",
    "\n",
    "    # Apply custom label mapping for display\n",
    "    custom_labels = [roi_label_map.get(lbl, lbl.upper()) for lbl in original_roi_order]\n",
    "    ax.set_xticklabels(custom_labels, rotation=60)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylim(-0.1,0.37)\n",
    "\n",
    "    # Move the legend to the top right corner\n",
    "    if ax.legend_ is not None:\n",
    "        ax.legend_.set_title(\"ROI category\")\n",
    "        ax.legend_.set_bbox_to_anchor((1.05, 1))\n",
    "\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.ylim(-0.1, 0.37)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Get the order of ROIs and hues as plotted\n",
    "    roi_order = [label.get_text() for label in ax.get_xticklabels()]\n",
    "    hue_order = list(deepgaze_df['roi_category'].dropna().unique())\n",
    "    n_hue = len(hue_order)\n",
    "    n_roi = len(roi_order)\n",
    "\n",
    "    ######################################################################################################################################\n",
    "    #Load the fdr_corrected p_values per ROI and subject from the subjectwiese df geneated in 03_analysis, while performing the ttest\n",
    "    # Create a lookup for p-values\n",
    "\n",
    "    for sub_num_inner_loop in range(1, 9): # Renamed to avoid conflict\n",
    "        # Define the subject-specific results path dynamically \n",
    "        RESULTS_PATH_subj = RESULTS_PATH / f'subj0{sub_num_inner_loop}'\n",
    "        # Load the DataFrame with FDR-corrected p-values\n",
    "        # Assuming sal_model is defined elsewhere or you want to use a specific one\n",
    "        current_sal_model = 'AllFixations' # Placeholder, adjust as needed\n",
    "        df_singlesub_fdr= pd.read_csv(RESULTS_PATH_subj / f'roi_means_subj0{sub_num_inner_loop}_{current_sal_model}_fdr_corrected.csv', index_col=False)\n",
    "    \n",
    "    # Add significance stars using p-values\n",
    "    for i, bar in enumerate(ax.patches[:len(original_roi_order)]):\n",
    "        roi = original_roi_order[i]\n",
    "        match = df_singlesub_fdr[df_singlesub_fdr['ROI'] == roi]\n",
    "        \n",
    "        # \n",
    "        if match.empty or pd.isnull(match['FDR-corrected p-value'].values[0]):\n",
    "            continue\n",
    "        p_value = match['FDR-corrected p-value'].values[0]\n",
    "        # Only print stars if the correlation (bar height) is positive\n",
    "        if bar.get_height() > 0:\n",
    "            if p_value < 0.001:\n",
    "                significance = '***'\n",
    "            elif p_value < 0.01:\n",
    "                significance = '**'\n",
    "            elif p_value < 0.05:\n",
    "                significance = '*'\n",
    "            else:\n",
    "                significance = ''\n",
    "            if significance:\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width() / 2,\n",
    "                    bar.get_height() + 0.01, # Adjusted y-offset\n",
    "                    significance,\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=14, color='red'\n",
    "                )\n",
    "\n",
    "    plt.savefig(RESULTS_PATH / f'eyetracking_AllFixations_mean_correlation_sig_subj0{sub_num}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(RESULTS_PATH / f'eyetracking_AllFixations_mean_correlation_sig_subj0{sub_num}.svg', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c968908",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_num in range(1, 9):\n",
    "    # Subjectwise Data Path Storage\n",
    "    DATA_PATH_subj = DATA_PATH / f'subjectwise_data/subject0{sub_num}'\n",
    "    # Filter for DeepGaze and the current subject\n",
    "    deepgaze_df = pd.read_csv(DATA_PATH_subj / f'corr_mat_all_rois_deepgazeIIE_subj0{sub_num}.csv')\n",
    "    if deepgaze_df.empty:\n",
    "        print(f\"No data for subject {sub_num}\")\n",
    "        continue\n",
    "\n",
    "    # Map ROI to category\n",
    "    roi_to_category = {}\n",
    "    for category, (rois, _) in roi_categories.items():\n",
    "        for roi in rois:\n",
    "            roi_to_category[roi] = category\n",
    "    deepgaze_df['roi_category'] = deepgaze_df['ROI'].map(roi_to_category)\n",
    "\n",
    "    # Create a grouped ROI order: all ROIs grouped by category order\n",
    "    grouped_roi_order = []\n",
    "    for category, (rois, _) in roi_categories.items():\n",
    "        grouped_roi_order.extend(rois)\n",
    "    # Filter to only those present in the DataFrame\n",
    "    grouped_roi_order = [roi for roi in grouped_roi_order if roi in deepgaze_df['ROI'].values]\n",
    "\n",
    "    # Use hue and a palette mapping category to color\n",
    "    category_palette = {cat: color for cat, (_, color) in roi_categories.items()}\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    ax = sns.barplot(\n",
    "        data=deepgaze_df, x='ROI', y='r_value',\n",
    "        hue='roi_category', palette=category_palette,\n",
    "        estimator=lambda x: np.tanh(np.mean(np.arctanh(x))),\n",
    "        errorbar='sd',\n",
    "        order=grouped_roi_order  # Use the sorted ROIs defined earlier\n",
    "    )\n",
    "    # Ensure gridlines are behind the bars\n",
    "    ax.set_axisbelow(True)\n",
    "    # Add vertical gridlines\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.xlabel(\"ROI\")\n",
    "    plt.ylabel(\"Mean Correlation (r)\")\n",
    "    plt.title(f\"Mean Correlation per ROI - DeepGaze, Subject 0{sub_num}\")\n",
    "\n",
    "    # Define custom ROI label mapping\n",
    "    roi_label_map = {\n",
    "        'v4': 'hV4',\n",
    "        'hmt': 'hMT',\n",
    "        'mtl_faces': 'MTL-faces',\n",
    "        'mtl_bodies': 'MTL-bodies',\n",
    "        'mfs_words': 'MFS-words',\n",
    "        'mtl_words': 'MTL-words',\n",
    "        'owfa': 'OVWFA',\n",
    "    }\n",
    "\n",
    "    # Get current x-tick labels (original ROI names)\n",
    "    original_roi_order = [label.get_text() for label in ax.get_xticklabels()]\n",
    "    custom_labels = [roi_label_map.get(lbl, lbl.upper()) for lbl in original_roi_order]\n",
    "    ax.set_xticklabels(custom_labels, rotation=60)\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.ylim(-0.1, 0.37)\n",
    "\n",
    "    # Move the legend to the top right corner\n",
    "    if ax.legend_ is not None:\n",
    "        ax.legend_.set_bbox_to_anchor((1.05, 1))\n",
    "\n",
    "    ######################################################################################################################################\n",
    "    # Load the fdr_corrected p_values per ROI and subject from the subjectwise df geneated in 03_analysis, while performing the t-test\n",
    "    # Create a lookup for p-values\n",
    "\n",
    "    for sub_num_inner_loop in range(1, 9): # Renamed to avoid conflict\n",
    "        # Define the subject-specific results path dynamically \n",
    "        RESULTS_PATH_subj = RESULTS_PATH / f'subj0{sub_num_inner_loop}'\n",
    "        # Load the DataFrame with FDR-corrected p-values\n",
    "        # Assuming sal_model is defined elsewhere or you want to use a specific one\n",
    "        current_sal_model = 'DeepGaze' # Placeholder, adjust as needed\n",
    "        df_singlesub_fdr= pd.read_csv(RESULTS_PATH_subj / f'roi_means_subj0{sub_num_inner_loop}_{current_sal_model}_fdr_corrected.csv', index_col=False)\n",
    "\n",
    "    # Save the updated DataFrame with FDR correction results\n",
    "    \n",
    "    # Add significance stars using p-values\n",
    "    for i, bar in enumerate(ax.patches[:len(original_roi_order)]):\n",
    "        roi = original_roi_order[i]\n",
    "        match = df_singlesub_fdr[df_singlesub_fdr['ROI'] == roi]\n",
    "        \n",
    "        # \n",
    "        if match.empty or pd.isnull(match['FDR-corrected p-value'].values[0]):\n",
    "            continue\n",
    "        p_value = match['FDR-corrected p-value'].values[0]\n",
    "\n",
    "        # Only print stars if the correlation (bar height) is positive\n",
    "        if bar.get_height() > 0:\n",
    "            if p_value < 0.001:\n",
    "                significance = '***'\n",
    "            elif p_value < 0.01:\n",
    "                significance = '**'\n",
    "            elif p_value < 0.05:\n",
    "                significance = '*'\n",
    "            else:\n",
    "                significance = ''\n",
    "            if significance:\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width() / 2,\n",
    "                    bar.get_height() + 0.01, # Adjusted y-Offset\n",
    "                    significance,\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=14, color='red'\n",
    "                )\n",
    "\n",
    "    plt.savefig(RESULTS_PATH / f'deepgaze_mean_correlation_sig_subj0{sub_num}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(RESULTS_PATH / f'deepgaze_mean_correlation_sig_subj0{sub_num}.svg', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e14cb",
   "metadata": {},
   "source": [
    "## Rank df_mean_roi_stats for the highest and lowest ROI value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770432a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the rois with th 4 highest mean r values\n",
    "# Sort the DataFrame by mean r value in descending order\n",
    "df_mean_roi_stats_ranked = df_mean_roi_stats.sort_values(by='Mean_r', ascending=False)\n",
    "# Print the top 4 ROIs with the highest mean r values\n",
    "top_rois = df_mean_roi_stats_ranked.head(4)\n",
    "print(\"Top 4 ROIs with highest mean r values:\")\n",
    "print(top_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6be58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print ranked \n",
    "df_mean_roi_stats_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db447138",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57098bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the aggregated, ranked DataFrame to a CSV file  \n",
    "# df_mean_roi_stats_ranked.to_csv(RESULTS_PATH / f'df_mean_roi_stat_ranked_all_subjects_{sal_model}_fdr_corrected_ranked.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080edb8b",
   "metadata": {},
   "source": [
    "## Paired t-tests: Is the correlation of the two saliency models (DeepGaze IIE or GroudTruthEyeTrackingData) significantly different?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f3bce",
   "metadata": {},
   "source": [
    "Compute the mean and STD deviance of the model difference per ROI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38abbd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Compute model difference per ROI per subject\n",
    "model_diff_results = []\n",
    "\n",
    "for roi in all_df['ROI'].unique():\n",
    "    dg = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == 'DeepGaze')][['subject', 'pearsonr']]\n",
    "    et = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == 'GroundTruthEyeTracking')][['subject', 'pearsonr']]\n",
    "    merged = pd.merge(dg, et, on='subject', suffixes=('_dg', '_et'))\n",
    "    if not merged.empty:\n",
    "        merged['model_diff'] = merged['pearsonr_dg'] - merged['pearsonr_et']\n",
    "        for _, row in merged.iterrows():\n",
    "            model_diff_results.append({\n",
    "                'ROI': roi,\n",
    "                'subject': row['subject'],\n",
    "                'model_diff': row['model_diff']\n",
    "            })\n",
    "\n",
    "model_diff_df = pd.DataFrame(model_diff_results)\n",
    "print(model_diff_df.head())\n",
    "\n",
    "# To get the mean and std of the difference per ROI:\n",
    "roi_diff_summary = model_diff_df.groupby('ROI')['model_diff'].agg(['mean', 'std', 'count']).reset_index()\n",
    "print(roi_diff_summary) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718244be",
   "metadata": {},
   "source": [
    "## Repeated Measures ANOVA to evaluate the performance of all three models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54febc01",
   "metadata": {},
   "source": [
    "Since we implemented another model. Let's perform a repeated measures ANOVA - this is appropiate two compare three or more models. \n",
    "\n",
    "- If the ANOVA is significant, I can follow up with posthoc- pairwise comparisons in the (with correction) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760fdf3b",
   "metadata": {},
   "source": [
    "First small test for a single roi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a4bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only the models you want to compare (e.g., three models)\n",
    "models_of_interest = ['GroundTruthEyeTracking', 'AllFixations', 'DeepGaze']\n",
    "df_anova = all_df[all_df['sal_model'].isin(models_of_interest)].copy()\n",
    "\n",
    "# Example: repeated measures ANOVA for a single ROI\n",
    "roi = 'v1'\n",
    "df_roi = df_anova[df_anova['ROI'] == roi]\n",
    "\n",
    "# Wide format for ANOVA\n",
    "df_wide = df_roi.pivot(index='subject', columns='sal_model', values='pearsonr').dropna()\n",
    "\n",
    "# Melt to long format for statsmodels\n",
    "df_long = df_wide.reset_index().melt(id_vars='subject', var_name='sal_model', value_name='pearsonr')\n",
    "\n",
    "# Run repeated measures ANOVA\n",
    "aovrm = sm.stats.AnovaRM(df_long, 'pearsonr', 'subject', within=['sal_model'])\n",
    "anova_results = aovrm.fit()\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b26b9",
   "metadata": {},
   "source": [
    "Then for all ROIs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only the models you want to compare (e.g., three models)\n",
    "models_of_interest = ['GroundTruthEyeTracking', 'AllFixations', 'DeepGaze']\n",
    "df_anova = all_df[all_df['sal_model'].isin(models_of_interest)].copy()\n",
    "\n",
    "anova_results_list = []\n",
    "\n",
    "for roi in sorted_rois:\n",
    "    df_roi = df_anova[df_anova['ROI'] == roi]\n",
    "    df_wide = df_roi.pivot(index='subject', columns='sal_model', values='pearsonr').dropna()\n",
    "    if df_wide.shape[0] < 2:  # Need at least 2 subjects for ANOVA\n",
    "        continue\n",
    "    df_long = df_wide.reset_index().melt(id_vars='subject', var_name='sal_model', value_name='pearsonr')\n",
    "    try:\n",
    "        aovrm = sm.stats.AnovaRM(df_long, 'pearsonr', 'subject', within=['sal_model'])\n",
    "        anova = aovrm.fit()\n",
    "        p_value = anova.anova_table['Pr > F'][0]\n",
    "        f_value = anova.anova_table['F Value'][0]\n",
    "        num_df = anova.anova_table['Num DF'][0]\n",
    "        den_df = anova.anova_table['Den DF'][0]\n",
    "\n",
    "         # Calculate partial eta squared from the F-value, and the two degrees of freedom associated with an F-test \n",
    "         # nominater and denominater degrees of freedom\n",
    "         # according to Daniel Lakens \n",
    "         #  https://sites.google.com/site/lakens2/blog/thefirstruleofnotunderstandingeffectsizesisyoudon%E2%80%99ttalkaboutnotunderstandingeffectsizes\n",
    "        ms_effect =  f_value * num_df # MS_effect = F Value times (k-1) K = number of saliency models \n",
    "        #df_d = 8-1  # df_d = n_subjects - 1\n",
    "        #partial_eta_squared = ms_effect / (ms_effect + df_d)\n",
    "\n",
    "        partial_eta_squared = ms_effect / (ms_effect + den_df)\n",
    "        partial_eta_squared = f_value / (f_value + (den_df / num_df))\n",
    "\n",
    "        # Correct SEM calculation\n",
    "        #sem = df_wide.std(axis=0) / np.sqrt(df_wide.shape[0])  # SD / sqrt(n)\n",
    "        #sem = sem.reset_index()\n",
    "        #sem.rename(columns={0: 'SEM'}, inplace=True)\n",
    "\n",
    "        # Calculate SEM and confidence intervals for each saliency model\n",
    "        ci_results = []\n",
    "        for sal_model in df_long['sal_model'].unique():\n",
    "            group_data = df_long[df_long['sal_model'] == sal_model]['pearsonr']\n",
    "            mean = group_data.mean()\n",
    "            sem = group_data.std(ddof=1) / np.sqrt(len(group_data))  # Standard error\n",
    "            df = len(group_data) - 1  # Degrees of freedom\n",
    "            t_critical = t.ppf(0.975, df)  # 95% confidence level\n",
    "            lower_ci = mean - t_critical * sem\n",
    "            upper_ci = mean + t_critical * sem\n",
    "            ci_results.append({'sal_model': sal_model, 'mean_r': mean, 'lower_ci': lower_ci, 'upper_ci': upper_ci})\n",
    "\n",
    "        \"\"\"       # Also report the confidencand were is the sem in the dataframe\n",
    "        e intervals\n",
    "        # Calculate the 95% confidence intervals for each model\n",
    "        ci = df_long.groupby('sal_model')['pearsonr'].agg(lambda x: np.percentile(x, [2.5, 97.5])).reset_index()\n",
    "        ci[['lower_ci', 'upper_ci']] = pd.DataFrame(ci['pearsonr'].tolist(), index=ci.index)\n",
    "        ci.drop(columns=['pearsonr'], inplace=True)\n",
    "        # Merge CI back to the original DataFrame\n",
    "        df_long = df_long.merge(ci, on='sal_model', how='left') \"\"\"\n",
    " \n",
    "\n",
    "        anova_results_list.append({\n",
    "        'ROI': roi, \n",
    "        'F': f_value, \n",
    "        'p': p_value, \n",
    "        'partial_eta_squared': partial_eta_squared,\n",
    "        'n_subjects': df_wide.shape[0],\n",
    "        'CI': ci_results  # Store confidence intervals for each saliency model\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"ANOVA failed for ROI {roi}: {e}\")\n",
    "\n",
    "anova_results_df = pd.DataFrame(anova_results_list)\n",
    "\n",
    "# Apply FDR correction to the ANOVA p-values\n",
    "if not anova_results_df.empty and 'p' in anova_results_df.columns:\n",
    "    p_values_anova = anova_results_df['p'].dropna()\n",
    "    if len(p_values_anova) > 0:\n",
    "        reject, corrected_p_values_anova = multipletests(p_values_anova, method='fdr_bh')[:2]\n",
    "        \n",
    "        # Create a temporary DataFrame for corrected p-values to merge safely\n",
    "        # Handles cases where dropna() might change indices or length\n",
    "        temp_corrected_df = pd.DataFrame({\n",
    "            'p': p_values_anova, \n",
    "            'fdr_p_value': corrected_p_values_anova,\n",
    "            'significant_fdr': reject\n",
    "        })\n",
    "        \n",
    "        # Merge corrected p-values back into the original DataFrame\n",
    "        # Ensure we are merging on the original 'p' values to align correctly\n",
    "        # This requires 'p' to be unique for each row, or use index if alignment is guaranteed\n",
    "        # If 'p' values are not unique, merging on index might be safer if p_values_anova maintains original indexing\n",
    "        \n",
    "        # Assuming p_values_anova maintains original index from anova_results_df where 'p' was not NaN:\n",
    "        original_indices = p_values_anova.index\n",
    "        temp_corrected_df.index = original_indices\n",
    "\n",
    "        anova_results_df = anova_results_df.join(temp_corrected_df[['fdr_p_value', 'significant_fdr']])\n",
    "\n",
    "print(anova_results_df)\n",
    "\n",
    "# Optionally, save results\n",
    "anova_results_df.to_csv(RESULTS_PATH / 'anova_results_per_roi.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8152ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aovrm = sm.stats.AnovaRM(df_long, 'pearsonr', 'subject', within=['sal_model'])\n",
    "#anova = aovrm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b75ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_long['sal_model'].nunique() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06792f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" f = anova.anova_table['F Value'][0]\n",
    "df_n = anova.anova_table['Num DF'][0]\n",
    "df_d = anova.anova_table['Den DF'][0]\n",
    "\n",
    "partial_eta_squared = f * df_n / (f * df_n + df_d)\n",
    "print(f\"Partial eta squared: {partial_eta_squared}\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25787e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anova.anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bfc7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_df['sal_model'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f3569",
   "metadata": {},
   "source": [
    "## Post-hoc: Paired t-tests (undirected), for each ROI, of the r values for DeepGaze and GroundTruthEyeTracking differ significantly across subjects.\n",
    "\n",
    "only for the ROIs that were significant "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bd908a",
   "metadata": {},
   "source": [
    "DG - FirstFix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe32ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_ttest_results = []\n",
    "\n",
    "for roi in all_df['ROI'].unique():\n",
    "    dg = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == 'DeepGaze')][['subject', 'pearsonr']]\n",
    "    et = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == 'GroundTruthEyeTracking')][['subject', 'pearsonr']]\n",
    "    merged = pd.merge(dg, et, on='subject', suffixes=('_dg', '_et'))\n",
    "    if len(merged) > 1:\n",
    "    # Only consider fdr corercted p-values smaller than 0.05, labeled as significant\n",
    "        # get the significant_fdr values from the anova_results_df\n",
    "        significant_fdr = anova_results_df[anova_results_df['ROI'] == roi]['significant_fdr'].values[0]\n",
    "        if significant_fdr:\n",
    "            # Perform paired t-test\n",
    "            t_stat, p_value = ttest_rel(merged['pearsonr_dg'], merged['pearsonr_et'])\n",
    "            if p_value < 0.05:\n",
    "                paired_ttest_results.append({\n",
    "                    'ROI': roi,\n",
    "                    't_stat': t_stat,\n",
    "                    'p_value': p_value,\n",
    "                    'n_subjects': len(merged)\n",
    "                })\n",
    "\n",
    "paired_ttest_results_df = pd.DataFrame(paired_ttest_results)\n",
    "# Apply FDR correction to the paired t-test p-values\n",
    "multipletests(paired_ttest_results_df['p_value'], method='fdr_bh')\n",
    "# Create a temporary DataFrame for corrected p-values to merge safely\n",
    "corrected_p_values = multipletests(paired_ttest_results_df['p_value'], method='fdr_bh')[1]\n",
    "# Merge corrected p-values back into the original DataFrame\n",
    "paired_ttest_results_df['fdr_p_value'] = corrected_p_values\n",
    "# Add a column to indicate significance based on FDR-corrected p-values\n",
    "paired_ttest_results_df['significant_fdr'] = paired_ttest_results_df['fdr_p_value'] < 0.05\n",
    "#Caluculate cohens d for the paired t-test results: d= t/squarootn\n",
    "paired_ttest_results_df['cohens_d'] = paired_ttest_results_df['t_stat'] / (paired_ttest_results_df['n_subjects'] ** 0.5)\n",
    "\n",
    "\n",
    "print(paired_ttest_results_df)\n",
    "\n",
    "# Save the paired t-test results\n",
    "paired_ttest_results_df.to_csv(RESULTS_PATH / 'paired_ttest_results_etFirst_dg.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba8e608",
   "metadata": {},
   "source": [
    "AllFix - DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_ttest_results = []\n",
    "\n",
    "for roi in all_df['ROI'].unique():\n",
    "    \n",
    "    allFix = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == 'AllFixations')][['subject', 'pearsonr']]\n",
    "    dg = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == 'DeepGaze')][['subject', 'pearsonr']]\n",
    "    merged = pd.merge(allFix, dg, on='subject', suffixes=('_allFix', '_dg'))\n",
    "    if len(merged) > 1:\n",
    "\n",
    "    # Only consider fdr corercted p-values smaller than 0.05, labeled as significant\n",
    "        # get the significant_fdr values from the anova_results_df\n",
    "        significant_fdr = anova_results_df[anova_results_df['ROI'] == roi]['significant_fdr'].values[0]\n",
    "        if significant_fdr:\n",
    "            # Perform undirect pair t-test \n",
    "            t_stat, p_value = ttest_rel( merged['pearsonr_allFix', merged['pearsonr_dg'],])\n",
    "            if p_value < 0.05:\n",
    "                paired_ttest_results.append({\n",
    "                    'ROI': roi,\n",
    "                    't_stat': t_stat,\n",
    "                    'p_value': p_value,\n",
    "                    'n_subjects': len(merged)\n",
    "                })\n",
    "\n",
    "paired_ttest_results_df = pd.DataFrame(paired_ttest_results)\n",
    "# Apply FDR correction to the paired t-test p-values\n",
    "multipletests(paired_ttest_results_df['p_value'], method='fdr_bh')\n",
    "# Create a temporary DataFrame for corrected p-values to merge safely\n",
    "corrected_p_values = multipletests(paired_ttest_results_df['p_value'], method='fdr_bh')[1]\n",
    "# Merge corrected p-values back into the original DataFrame\n",
    "paired_ttest_results_df['fdr_p_value'] = corrected_p_values\n",
    "# Add a column to indicate significance based on FDR-corrected p-values\n",
    "paired_ttest_results_df['significant_fdr'] = paired_ttest_results_df['fdr_p_value'] < 0.05\n",
    "#Caluculate cohens d for the paired t-test results: d= t/squarootn\n",
    "paired_ttest_results_df['cohens_d'] = paired_ttest_results_df['t_stat'] / (paired_ttest_results_df['n_subjects'] ** 0.5)\n",
    "\n",
    "print(paired_ttest_results_df)\n",
    "# Save the paired t-test results\n",
    "paired_ttest_results_df.to_csv(RESULTS_PATH / 'paired_ttest_results_allFix_dg.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257891a5",
   "metadata": {},
   "source": [
    "AllFix - FirstFix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_ttest_results = []\n",
    "\n",
    "for roi in all_df['ROI'].unique():\n",
    "    \n",
    "    \n",
    "    allFix = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == 'AllFixations')][['subject', 'pearsonr']]\n",
    "    et = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == 'GroundTruthEyeTracking')][['subject', 'pearsonr']]\n",
    "    \n",
    "    merged = pd.merge(allFix, et, on='subject', suffixes=('_allFix', '_et'))\n",
    "    if len(merged) > 1:\n",
    "    # Only consider fdr corrected p-values smaller than 0.05, labeled as significant\n",
    "        # get the significant_fdr values from the anova_results_df\n",
    "        significant_fdr = anova_results_df[anova_results_df['ROI'] == roi]['significant_fdr'].values[0]\n",
    "        if significant_fdr:\n",
    "            # Perform paired t-test\n",
    "            t_stat, p_value = ttest_rel(merged['pearsonr_et'], merged['pearsonr_allFix'])\n",
    "            if p_value < 0.05:\n",
    "                paired_ttest_results.append({\n",
    "                    'ROI': roi,\n",
    "                    't_stat': t_stat,\n",
    "                    'p_value': p_value,\n",
    "                    'n_subjects': len(merged)\n",
    "                })\n",
    "\n",
    "paired_ttest_results_df = pd.DataFrame(paired_ttest_results)\n",
    "# Apply FDR correction to the paired t-test p-values\n",
    "multipletests(paired_ttest_results_df['p_value'], method='fdr_bh')\n",
    "# Create a temporary DataFrame for corrected p-values to merge safely\n",
    "corrected_p_values = multipletests(paired_ttest_results_df['p_value'], method='fdr_bh')[1]\n",
    "# Merge corrected p-values back into the original DataFrame\n",
    "paired_ttest_results_df['fdr_p_value'] = corrected_p_values\n",
    "# Add a column to indicate significance based on FDR-corrected p-values\n",
    "paired_ttest_results_df['significant_fdr'] = paired_ttest_results_df['fdr_p_value'] < 0.05\n",
    "#Caluculate cohens d for the paired t-test results: d= t/squarootn\n",
    "paired_ttest_results_df['cohens_d'] = paired_ttest_results_df['t_stat'] / (paired_ttest_results_df['n_subjects'] ** 0.5)\n",
    "\n",
    "print(paired_ttest_results_df)\n",
    "# Save the paired t-test results\n",
    "paired_ttest_results_df.to_csv(RESULTS_PATH / 'paired_ttest_results_etFirst_allFix.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3cd4ec",
   "metadata": {},
   "source": [
    "## Model comparison averaged over all ROIs undirected paired t-tests "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b284d14",
   "metadata": {},
   "source": [
    "AllFix - FirstFix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d72af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaged over all ROIs paired t-test two tailed \n",
    "\n",
    "# Ensure both models have the same number of subjects and ROIs = paired observations\n",
    "merged = pd.merge(\n",
    "    all_df[all_df['sal_model'] == 'AllFixations'][['subject', 'ROI', 'pearsonr']],\n",
    "    all_df[all_df['sal_model'] == 'GroundTruthEyeTracking'][['subject', 'ROI', 'pearsonr']],\n",
    "    on=['subject', 'ROI'],\n",
    "    suffixes=('_allFix', '_et')\n",
    ")\n",
    "\n",
    "print(f\"Number of n: {len(merged)}\")\n",
    "\n",
    "# Perform the two-tailed paired t-test\n",
    "t_stat, p_value = ttest_rel(merged['pearsonr_allFix'], merged['pearsonr_et'])\n",
    "# Add cohens d for the averaged results \n",
    "cohens_d = t_stat / (len(merged) ** 0.5)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Paired t-test across all ROIs:\")\n",
    "print(f\"t-statistic: {t_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Cohen's d: {cohens_d:.3f}\")\n",
    "\n",
    "# Check significance\n",
    "if p_value < 0.05:\n",
    "    print(\"The results are significant across all ROIs.\")\n",
    "else:\n",
    "    print(\"The results are not significant across all ROIs.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b6e6dc",
   "metadata": {},
   "source": [
    "Same for DG and FirstFix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94087b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaged over all ROIs paired t-test two tailed \n",
    "\n",
    "# Ensure both models have the same number of subjects and ROIs\n",
    "merged = pd.merge(\n",
    "    all_df[all_df['sal_model'] == 'DeepGaze'][['subject', 'ROI', 'pearsonr']],\n",
    "    all_df[all_df['sal_model'] == 'GroundTruthEyeTracking'][['subject', 'ROI', 'pearsonr']],\n",
    "    on=['subject', 'ROI'],\n",
    "    suffixes=('_dg', '_et')\n",
    ")\n",
    "\n",
    "# Perform the two-tailed paired t-test\n",
    "t_stat, p_value = ttest_rel(merged['pearsonr_dg'], merged['pearsonr_et'])\n",
    "# Add cohens d for the averaged results \n",
    "cohens_d = t_stat / (len(merged) ** 0.5)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Paired t-test across all ROIs:\")\n",
    "print(f\"t-statistic: {t_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Cohen's d: {cohens_d:.3f}\")\n",
    "\n",
    "# Check significance\n",
    "if p_value < 0.05:\n",
    "    print(\"The results are significant across all ROIs.\")\n",
    "else:\n",
    "    print(\"The results are not significant across all ROIs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43c2d9",
   "metadata": {},
   "source": [
    "Same for DG and AllFix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaged over all ROIs paired t-test two tailed \n",
    "\n",
    "# Ensure both models have the same number of subjects and ROIs\n",
    "merged = pd.merge(\n",
    "    all_df[all_df['sal_model'] == 'DeepGaze'][['subject', 'ROI', 'pearsonr']],\n",
    "    all_df[all_df['sal_model'] == 'AllFixations'][['subject', 'ROI', 'pearsonr']],\n",
    "    on=['subject', 'ROI'],\n",
    "    suffixes=('_dg', '_allFix')\n",
    ")\n",
    "\n",
    "# Perform the two-tailed paired t-test\n",
    "t_stat, p_value = ttest_rel(merged['pearsonr_dg'], merged['pearsonr_allFix'])\n",
    "# Add cohens d for the averaged results \n",
    "cohens_d = t_stat / (len(merged) ** 0.5)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Paired t-test across all ROIs:\")\n",
    "print(f\"t-statistic: {t_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Cohen's d: {cohens_d:.3f}\")\n",
    "\n",
    "# Check significance\n",
    "if p_value < 0.05:\n",
    "    print(\"The results are significant across all ROIs.\")\n",
    "else:\n",
    "    print(\"The results are not significant across all ROIs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04750ae1",
   "metadata": {},
   "source": [
    "### Now execution of directed t-tests "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335b4128",
   "metadata": {},
   "source": [
    "Now perform paired (directed) t-tests to test for the direction of the differences in between the prediction of the saliency models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a directed paired t-test between the two models\n",
    "paired_ttest_results_directed = []\n",
    "\n",
    "for roi in all_df['ROI'].unique():\n",
    "\n",
    "    allFix = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == 'AllFixations')][['subject', 'pearsonr']]\n",
    "    et = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == 'GroundTruthEyeTracking')][['subject', 'pearsonr']]\n",
    "    \n",
    "    merged = pd.merge(allFix, et, on='subject', suffixes=('_allFix', '_et'))\n",
    "    if len(merged) > 1:\n",
    "    # Only consider fdr corrected p-values smaller than 0.05, labeled as significant\n",
    "        # get the significant_fdr values from the anova_results_df\n",
    "        significant_fdr = anova_results_df[anova_results_df['ROI'] == roi]['significant_fdr'].values[0]\n",
    "        if significant_fdr:\n",
    "            # Perform directed paired t-test \n",
    "            t_stat, p_value = ttest_rel(merged['pearsonr_allFix'], merged['pearsonr_et'], alternative='greater')\n",
    "            if p_value < 0.05:\n",
    "                paired_ttest_results_directed.append({\n",
    "                    'ROI': roi,\n",
    "                    't_stat': t_stat,\n",
    "                    'p_value': p_value,\n",
    "                    'n_subjects': len(merged)\n",
    "                })\n",
    "\n",
    "paired_ttest_results_df_directed = pd.DataFrame(paired_ttest_results_directed)\n",
    "# Apply FDR correction to the paired t-test p-values\n",
    "multipletests(paired_ttest_results_df_directed['p_value'], method='fdr_bh')\n",
    "# Create a temporary DataFrame for corrected p-values to merge safely\n",
    "corrected_p_values = multipletests(paired_ttest_results_df_directed['p_value'], method='fdr_bh')[1]\n",
    "# Merge corrected p-values back into the original DataFrame\n",
    "paired_ttest_results_df_directed['fdr_p_value'] = corrected_p_values\n",
    "# Add a column to indicate significance based on FDR-corrected p-values\n",
    "paired_ttest_results_df_directed['significant_fdr'] = paired_ttest_results_df_directed['fdr_p_value'] < 0.05\n",
    "#Caluculate cohens d for the paired t-test results: d= t/squarootn\n",
    "paired_ttest_results_df_directed['cohens_d'] = paired_ttest_results_df_directed['t_stat'] / (paired_ttest_results_df_directed['n_subjects'] ** 0.5)\n",
    "\n",
    "print(paired_ttest_results_df_directed)\n",
    "# Save the paired t-test results\n",
    "paired_ttest_results_df_directed.to_csv(RESULTS_PATH / 'paired_ttest_results_directed_allFix_firstFix.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eea4d4",
   "metadata": {},
   "source": [
    "Directed paired t-test for DeepGaze IIE and First-Fixation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c095210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a directed paired t-test between the two models\n",
    "paired_ttest_results_directed = []\n",
    "\n",
    "for roi in all_df['ROI'].unique():\n",
    "\n",
    "    dg = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == 'DeepGaze')][['subject', 'pearsonr']]\n",
    "    et = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == 'GroundTruthEyeTracking')][['subject', 'pearsonr']]\n",
    "    merged = pd.merge(dg, et, on='subject', suffixes=('_dg', '_et'))\n",
    "    if len(merged) > 1:\n",
    "    # Only consider fdr corrected p-values smaller than 0.05, labeled as significant\n",
    "        # get the significant_fdr values from the anova_results_df\n",
    "        significant_fdr = anova_results_df[anova_results_df['ROI'] == roi]['significant_fdr'].values[0]\n",
    "        if significant_fdr:\n",
    "            # Perform directed paired t-test \n",
    "            t_stat, p_value = ttest_rel(merged['pearsonr_dg'], merged['pearsonr_et'], alternative='greater')\n",
    "            if p_value < 0.05:\n",
    "                paired_ttest_results_directed.append({\n",
    "                    'ROI': roi,\n",
    "                    't_stat': t_stat,\n",
    "                    'p_value': p_value,\n",
    "                    'n_subjects': len(merged)\n",
    "                })\n",
    "\n",
    "paired_ttest_results_df_directed = pd.DataFrame(paired_ttest_results_directed)\n",
    "# Apply FDR correction to the paired t-test p-values\n",
    "multipletests(paired_ttest_results_df_directed['p_value'], method='fdr_bh')\n",
    "# Create a temporary DataFrame for corrected p-values to merge safely\n",
    "corrected_p_values = multipletests(paired_ttest_results_df_directed['p_value'], method='fdr_bh')[1]\n",
    "# Merge corrected p-values back into the original DataFrame\n",
    "paired_ttest_results_df_directed['fdr_p_value'] = corrected_p_values\n",
    "# Add a column to indicate significance based on FDR-corrected p-values\n",
    "paired_ttest_results_df_directed['significant_fdr'] = paired_ttest_results_df_directed['fdr_p_value'] < 0.05\n",
    "#Caluculate cohens d for the paired t-test results: d= t/squarootn\n",
    "paired_ttest_results_df_directed['cohens_d'] = paired_ttest_results_df_directed['t_stat'] / (paired_ttest_results_df_directed['n_subjects'] ** 0.5)\n",
    "\n",
    "print(paired_ttest_results_df_directed)\n",
    "# Save the paired t-test results\n",
    "paired_ttest_results_df_directed.to_csv(RESULTS_PATH / 'paired_ttest_results_directed_DG_firstFix.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284db8fc",
   "metadata": {},
   "source": [
    "Directed paired t-test for DG and All Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8b132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a directed paired t-test between the two models\n",
    "paired_ttest_results_directed = []\n",
    "\n",
    "for roi in all_df['ROI'].unique():\n",
    "\n",
    "    dg = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == 'DeepGaze')][['subject', 'pearsonr']]\n",
    "    allFix = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == 'AllFixations')][['subject', 'pearsonr']]\n",
    "    \n",
    "    merged = pd.merge(dg, allFix, on='subject', suffixes=('_dg','_allFix'))\n",
    "    if len(merged) > 1:\n",
    "    # Only consider fdr corrected p-values smaller than 0.05, labeled as significant\n",
    "        # get the significant_fdr values from the anova_results_df\n",
    "        significant_fdr = anova_results_df[anova_results_df['ROI'] == roi]['significant_fdr'].values[0]\n",
    "        if significant_fdr:\n",
    "            # Perform directed paired t-test \n",
    "            t_stat, p_value = ttest_rel(merged['pearsonr_dg'], merged['pearsonr_allFix'], alternative='greater')\n",
    "            if p_value < 0.05:\n",
    "                paired_ttest_results_directed.append({\n",
    "                    'ROI': roi,\n",
    "                    't_stat': t_stat,\n",
    "                    'p_value': p_value,\n",
    "                    'n_subjects': len(merged)\n",
    "                })\n",
    "\n",
    "paired_ttest_results_df_directed = pd.DataFrame(paired_ttest_results_directed)\n",
    "# Apply FDR correction to the paired t-test p-values\n",
    "multipletests(paired_ttest_results_df_directed['p_value'], method='fdr_bh')\n",
    "# Create a temporary DataFrame for corrected p-values to merge safely\n",
    "corrected_p_values = multipletests(paired_ttest_results_df_directed['p_value'], method='fdr_bh')[1]\n",
    "# Merge corrected p-values back into the original DataFrame\n",
    "paired_ttest_results_df_directed['fdr_p_value'] = corrected_p_values\n",
    "# Add a column to indicate significance based on FDR-corrected p-values\n",
    "paired_ttest_results_df_directed['significant_fdr'] = paired_ttest_results_df_directed['fdr_p_value'] < 0.05\n",
    "#Caluculate cohens d for the paired t-test results: d= t/squarootn\n",
    "paired_ttest_results_df_directed['cohens_d'] = paired_ttest_results_df_directed['t_stat'] / (paired_ttest_results_df_directed['n_subjects'] ** 0.5)\n",
    "\n",
    "print(paired_ttest_results_df_directed)\n",
    "# Save the paired t-test results\n",
    "paired_ttest_results_df_directed.to_csv(RESULTS_PATH / 'paired_ttest_results_directed_DG_allFix.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a72c02",
   "metadata": {},
   "source": [
    "Directed t-tests averaged over the whole sample and ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be084e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaged over all ROIs paired t-test two tailed \n",
    "\n",
    "# Ensure both models have the same number of subjects and ROIs\n",
    "merged = pd.merge(\n",
    "    all_df[all_df['sal_model'] == 'AllFixations'][['subject', 'ROI', 'pearsonr']],\n",
    "    all_df[all_df['sal_model'] == 'GroundTruthEyeTracking'][['subject', 'ROI', 'pearsonr']],\n",
    "    on=['subject', 'ROI'],\n",
    "    suffixes=('_allFix', '_et')\n",
    ")\n",
    "\n",
    "# Print n\n",
    "print(f\"Number of n: {len(merged)}\")\n",
    "\n",
    "# Perform the two-tailed paired t-test\n",
    "t_stat, p_value = ttest_rel(merged['pearsonr_allFix'], merged['pearsonr_et'], alternative = 'greater')\n",
    "# Add cohens d for the averaged results \n",
    "cohens_d = t_stat / (len(merged) ** 0.5)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Paired t-test across all ROIs:\")\n",
    "print(f\"t-statistic: {t_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Cohen's d: {cohens_d:.3f}\")\n",
    "\n",
    "# Check significance\n",
    "if p_value < 0.05:\n",
    "    print(\"The results are significant across all ROIs.\")\n",
    "else:\n",
    "    print(\"The results are not significant across all ROIs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d59d9ad",
   "metadata": {},
   "source": [
    "Same for DG and allFix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4912ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaged over all ROIs paired t-test two tailed \n",
    "\n",
    "# Ensure both models have the same number of subjects and ROIs\n",
    "merged = pd.merge(\n",
    "    all_df[all_df['sal_model'] == 'DeepGaze'][['subject', 'ROI', 'pearsonr']],\n",
    "    all_df[all_df['sal_model'] == 'AllFixations'][['subject', 'ROI', 'pearsonr']],\n",
    "    on=['subject', 'ROI'],\n",
    "    suffixes=('_dg', '_allFix')\n",
    ")\n",
    "# Print n\n",
    "print(f\"Number of n: {len(merged)}\")\n",
    "\n",
    "# Perform the two-tailed paired t-test\n",
    "t_stat, p_value = ttest_rel(merged['pearsonr_dg'], merged['pearsonr_allFix'], alternative='greater')\n",
    "# Add cohens d for the averaged results \n",
    "cohens_d = t_stat / (len(merged) ** 0.5)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Paired t-test across all ROIs:\")\n",
    "print(f\"t-statistic: {t_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Cohen's d: {cohens_d:.3f}\")\n",
    "\n",
    "# Check significance\n",
    "if p_value < 0.05:\n",
    "    print(\"The results are significant across all ROIs.\")\n",
    "else:\n",
    "    print(\"The results are not significant across all ROIs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565d04ea",
   "metadata": {},
   "source": [
    "Same for DG and FirstFix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eb96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaged over all ROIs paired t-test two tailed \n",
    "\n",
    "# Ensure both models have the same number of subjects and ROIs\n",
    "merged = pd.merge(\n",
    "    all_df[all_df['sal_model'] == 'DeepGaze'][['subject', 'ROI', 'pearsonr']],\n",
    "    all_df[all_df['sal_model'] == 'GroundTruthEyeTracking'][['subject', 'ROI', 'pearsonr']],\n",
    "    on=['subject', 'ROI'],\n",
    "    suffixes=('_dg', '_et')\n",
    ")\n",
    "# Print n\n",
    "print(f\"Number of n: {len(merged)}\")\n",
    "\n",
    "# Perform the two-tailed paired t-test\n",
    "t_stat, p_value = ttest_rel(merged['pearsonr_dg'], merged['pearsonr_et'], alternative='greater')\n",
    "# Add cohens d for the averaged results \n",
    "cohens_d = t_stat / (len(merged) ** 0.5)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Paired t-test across all ROIs:\")\n",
    "print(f\"t-statistic: {t_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Cohen's d: {cohens_d:.3f}\")\n",
    "\n",
    "# Check significance\n",
    "if p_value < 0.05:\n",
    "    print(\"The results are significant across all ROIs.\")\n",
    "else:\n",
    "    print(\"The results are not significant across all ROIs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f71f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc77256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_roi_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9410cd",
   "metadata": {},
   "source": [
    "## Plotting of model difference (Mean r across all ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25248cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new saliency model names and their desired order\n",
    "saliency_model_rename = {\n",
    "    'GroundTruthEyeTracking': 'Eye Tracking (First Fixation)',\n",
    "    'AllFixations': 'Eye Tracking (All Fixations)',\n",
    "    'DeepGaze': 'DeepGaze IIE'\n",
    "}\n",
    "desired_order = ['Eye Tracking (First Fixation)', 'Eye Tracking (All Fixations)', 'DeepGaze IIE']\n",
    "\n",
    "# Rename the saliency models in the DataFrame\n",
    "all_df['sal_model'] = all_df['sal_model'].map(saliency_model_rename)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "g = sns.catplot(\n",
    "    data=all_df, x='ROI', y='pearsonr', hue='sal_model',\n",
    "    kind='bar', height=6, aspect=2, palette='Set2', hue_order=desired_order,\n",
    "    estimator=lambda x: np.tanh(np.mean(np.arctanh(x)))\n",
    ")\n",
    "\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"ROI\", \"Mean Correlation (r)\")\n",
    "# Access the legend and set its title\n",
    "if g.legend is not None:\n",
    "    g.legend.set_title(\"Saliency Model\")\n",
    "\n",
    "#######################################################################################################################################\n",
    "# Define custom ROI label mapping - so that the labels of the plot are coherent with the thesis and literature \n",
    "roi_label_map = {\n",
    "    'v4': 'hV4',\n",
    "    'hmt': 'hMT',\n",
    "    'mtl_faces': 'MTL-faces',\n",
    "    'mtl_bodies': 'MTL-bodies',\n",
    "    'mfs_words': 'MFS-words',\n",
    "    'mtl_words': 'MTL-words',\n",
    "    'owfa': 'OVWFA',\n",
    "}\n",
    "\n",
    "# Get current x-tick labels (original ROI names)\n",
    "ax = g.ax if hasattr(g, 'ax') else g.axes.flat[0]  # Access the correct axis\n",
    "original_roi_order = [label.get_text() for label in ax.get_xticklabels()]\n",
    "\n",
    "# Apply custom label mapping for display\n",
    "custom_labels = [roi_label_map.get(lbl, lbl.upper()) for lbl in original_roi_order]\n",
    "ax.set_xticklabels(custom_labels, rotation=60)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylim(-0.1,0.18)\n",
    "\n",
    "ax = g.ax\n",
    "\n",
    "# Move the legend to the top right corner\n",
    "if g.legend is not None:\n",
    "    g.legend.set_bbox_to_anchor((1.05, 1))\n",
    "\n",
    "# Use original ROI names for lookup, but display custom labels\n",
    "roi_order = original_roi_order\n",
    "saliency_order = [t.get_text() for t in g.legend.texts]\n",
    "n_roi = len(roi_order)\n",
    "n_sal = len(saliency_order)\n",
    "#######################################################################################################################################\n",
    "# Look for the FDR corrected p-values in the all_df dataframe\n",
    "for i, bar in enumerate(ax.patches):\n",
    "    roi_idx = i % n_roi\n",
    "    sal_idx = i // n_roi\n",
    "    if roi_idx >= n_roi or sal_idx >= n_sal:\n",
    "        continue\n",
    "    roi = roi_order[roi_idx]  # This is the original ROI name\n",
    "    sal_model = saliency_order[sal_idx]\n",
    "    # Try to get the p-value, skip if missing\n",
    "    match = all_df[(all_df['ROI'] == roi) & (all_df['sal_model'] == sal_model)]\n",
    "    if match.empty or pd.isnull(match['fdr_p_value'].values[0]):\n",
    "        continue\n",
    "    p_value = match['fdr_p_value'].values[0]\n",
    "    # Determine significance stars\n",
    "    if p_value < 0.001:\n",
    "        significance = '***'\n",
    "    elif p_value < 0.01:\n",
    "        significance = '**'\n",
    "    elif p_value < 0.05:\n",
    "        significance = '*'\n",
    "    else:\n",
    "        significance = ''\n",
    "\n",
    "    # Add the stars above the bar\n",
    "    if significance:\n",
    "        g.ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.05,\n",
    "                significance, ha='center', va='bottom', fontsize=12, color='red')\n",
    "        \n",
    "# Save the plot to a file\n",
    "plt.savefig(RESULTS_PATH / 'combined_mean_correlation_sig_all_subjects_fdr_corrected.png', dpi=300, bbox_inches='tight')\n",
    "# Save as SVG\n",
    "plt.savefig(RESULTS_PATH / 'combined_mean_correlation_sig_all_subjects_fdr_corrected.svg', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
